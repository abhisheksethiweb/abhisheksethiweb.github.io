<!-- udacimak v1.2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Bellman Equations</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>The RL Framework: The Solution</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Introduction.html">01. Introduction</a>
    </li>
    <li class="">
      <a href="02. Policies.html">02. Policies</a>
    </li>
    <li class="">
      <a href="03. Quiz Interpret the Policy.html">03. Quiz: Interpret the Policy</a>
    </li>
    <li class="">
      <a href="04. Gridworld Example.html">04. Gridworld Example</a>
    </li>
    <li class="">
      <a href="05. State-Value Functions.html">05. State-Value Functions</a>
    </li>
    <li class="">
      <a href="06. Bellman Equations.html">06. Bellman Equations</a>
    </li>
    <li class="">
      <a href="07. Quiz State-Value Functions.html">07. Quiz: State-Value Functions</a>
    </li>
    <li class="">
      <a href="08. Optimality.html">08. Optimality</a>
    </li>
    <li class="">
      <a href="09. Action-Value Functions.html">09. Action-Value Functions</a>
    </li>
    <li class="">
      <a href="10. Quiz Action-Value Functions.html">10. Quiz: Action-Value Functions</a>
    </li>
    <li class="">
      <a href="11. Optimal Policies.html">11. Optimal Policies</a>
    </li>
    <li class="">
      <a href="12. Quiz Optimal Policies.html">12. Quiz: Optimal Policies</a>
    </li>
    <li class="">
      <a href="13. Summary.html">13. Summary</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">06. Bellman Equations</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3><p>Bellman Equations</p></h3>
  <video controls>
  <source src="06. Bellman Equations-UgIaDMvSdUo.mp4" type="video/mp4">

  <track default="true" kind="subtitles" srclang="en" src="06. Bellman Equations-UgIaDMvSdUo.en.vtt" label="en">
  <track default="false" kind="subtitles" srclang="BR" src="06. Bellman Equations-UgIaDMvSdUo.pt-BR.vtt" label="BR">
  <track default="false" kind="subtitles" srclang="CN" src="06. Bellman Equations-UgIaDMvSdUo.zh-CN.vtt" label="CN">
</video>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h1 id="bellman-equations">Bellman Equations</h1>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>In this gridworld example, once the agent selects an action, </p>
<ul>
<li>it always moves in the chosen direction (contrasting general MDPs where the agent doesn't always have complete control over what the next state will be), and </li>
<li>the reward can be predicted with complete certainty (contrasting general MDPs where the reward is a random draw from a probability distribution).</li>
</ul>
<p>In this simple example, we saw that the value of any state can be calculated as the sum of the immediate reward and the (discounted) value of the next state.  </p>
<p>Alexis mentioned that for a general MDP, we have to instead work in terms of an <em>expectation</em>, since it's not often the case that the immediate reward and next state can be predicted with certainty.  Indeed, we saw in an earlier lesson that the reward and next state are chosen according to the one-step dynamics of the MDP.  In this case, where the reward <span class="mathquill ud-math">r</span> and next state <span class="mathquill ud-math">s'</span> are drawn from a (conditional) probability distribution <span class="mathquill ud-math">p(s',r|s,a)</span>, the <strong>Bellman Expectation Equation (for <span class="mathquill ud-math">v_\pi</span>)</strong> expresses the value of any state <span class="mathquill ud-math">s</span> in terms of the <em>expected</em> immediate reward and the  <em>expected</em> value of the next state:</p>
<div class="mathquill">v_\pi(s) = \text{} \mathbb{E}_\pi[R_{t+1} + \gamma v_\pi(S_{t+1})|S_t =s].</div>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-calculating-the-expectation">## Calculating the Expectation</h2>
<p>In the event that the agent's policy <span class="mathquill ud-math">\pi</span> is <strong>deterministic</strong>,  the agent selects action <span class="mathquill ud-math">\pi(s)</span> when in state <span class="mathquill ud-math">s</span>, and the Bellman Expectation Equation can be rewritten as the sum over two variables (<span class="mathquill ud-math">s'</span> and <span class="mathquill ud-math">r</span>):</p>
<div class="mathquill">v_\pi(s) = \text{} \sum_{s'\in\mathcal{S}^+, r\in\mathcal{R}}p(s',r|s,\pi(s))(r+\gamma  v_\pi(s'))</div>
<p>In this case, we multiply the sum of the reward and discounted value of the next state <span class="mathquill ud-math">(r+\gamma  v_\pi(s'))</span> by its corresponding probability <span class="mathquill ud-math">p(s',r|s,\pi(s))</span> and sum over all possibilities to yield the expected value.</p>
<p>If the agent's policy <span class="mathquill ud-math">\pi</span> is <strong>stochastic</strong>,  the agent selects action <span class="mathquill ud-math">a</span> with probability <span class="mathquill ud-math">\pi(a|s)</span> when in state <span class="mathquill ud-math">s</span>, and the Bellman Expectation Equation can be rewritten as the sum over three variables (<span class="mathquill ud-math">s'</span>, <span class="mathquill ud-math">r</span>, and <span class="mathquill ud-math">a</span>):</p>
<div class="mathquill">v_\pi(s) = \text{} \sum_{s'\in\mathcal{S}^+, r\in\mathcal{R},a\in\mathcal{A}(s)}\pi(a|s)p(s',r|s,a)(r+\gamma  v_\pi(s'))</div>
<p>In this case, we multiply the sum of the reward and discounted value of the next state <span class="mathquill ud-math">(r+\gamma  v_\pi(s'))</span> by its corresponding probability <span class="mathquill ud-math">\pi(a|s)p(s',r|s,a)</span> and sum over all possibilities to yield the expected value.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-there-are-3-more-bellman-equations">## There are 3 more Bellman Equations!</h2>
<p>In this video, you learned about one Bellman equation, but there are 3 more, for a total of 4 Bellman equations.</p>
<blockquote>
  <p>All of the Bellman equations attest to the fact that <em>value functions satisfy recursive relationships</em>.  </p>
</blockquote>
<p>For instance, the  <strong>Bellman Expectation Equation (for <span class="mathquill ud-math">v_\pi</span>)</strong> shows that it is possible to relate the value of a state to the values of all of its possible successor states.</p>
<p>After finishing this lesson, you are encouraged to read about the remaining three Bellman equations in sections 3.5 and 3.6 of the <a href="http://go.udacity.com/rl-textbook" target="_blank">textbook</a>.  The Bellman equations are incredibly useful to the theory of MDPs.</p>
</div>

</div>
<div class="divider"></div>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.2.0</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });
    });
  </script>
</body>

</html>
