<!-- udacimak v1.2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Summary</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>The RL Framework: The Solution</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Introduction.html">01. Introduction</a>
    </li>
    <li class="">
      <a href="02. Policies.html">02. Policies</a>
    </li>
    <li class="">
      <a href="03. Quiz Interpret the Policy.html">03. Quiz: Interpret the Policy</a>
    </li>
    <li class="">
      <a href="04. Gridworld Example.html">04. Gridworld Example</a>
    </li>
    <li class="">
      <a href="05. State-Value Functions.html">05. State-Value Functions</a>
    </li>
    <li class="">
      <a href="06. Bellman Equations.html">06. Bellman Equations</a>
    </li>
    <li class="">
      <a href="07. Quiz State-Value Functions.html">07. Quiz: State-Value Functions</a>
    </li>
    <li class="">
      <a href="08. Optimality.html">08. Optimality</a>
    </li>
    <li class="">
      <a href="09. Action-Value Functions.html">09. Action-Value Functions</a>
    </li>
    <li class="">
      <a href="10. Quiz Action-Value Functions.html">10. Quiz: Action-Value Functions</a>
    </li>
    <li class="">
      <a href="11. Optimal Policies.html">11. Optimal Policies</a>
    </li>
    <li class="">
      <a href="12. Quiz Optimal Policies.html">12. Quiz: Optimal Policies</a>
    </li>
    <li class="">
      <a href="13. Summary.html">13. Summary</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">13. Summary</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3></h3>
  <div>
  <h1 id="summary">Summary</h1>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/screen-shot-2017-09-25-at-11.35.38-am.png" alt="State-value function for golf-playing agent (Sutton and Barto, 2017)" class="img img-fluid">
    <figcaption class="figure-caption">
      <p>State-value function for golf-playing agent (Sutton and Barto, 2017)</p>
    </figcaption>
  </figure>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-policies">### Policies</h2>
<ul>
<li>A <strong>deterministic policy</strong> is a mapping <span class="mathquill ud-math">\pi: \mathcal{S}\to\mathcal{A}</span>.  For each state <span class="mathquill ud-math">s\in\mathcal{S}</span>, it yields the action <span class="mathquill ud-math">a\in\mathcal{A}</span> that the agent will choose while in state <span class="mathquill ud-math">s</span>.</li>
<li>A <strong>stochastic policy</strong> is a mapping <span class="mathquill ud-math">\pi: \mathcal{S}\times\mathcal{A}\to [0,1]</span>.  For each state <span class="mathquill ud-math">s\in\mathcal{S}</span> and action <span class="mathquill ud-math">a\in\mathcal{A}</span>, it yields the probability <span class="mathquill ud-math">\pi(a|s)</span> that the agent chooses action <span class="mathquill ud-math">a</span> while in state  <span class="mathquill ud-math">s</span>.</li>
</ul>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-state-value-functions">### State-Value Functions</h2>
<ul>
<li>The <strong>state-value function</strong> for a policy <span class="mathquill ud-math">\pi</span> is denoted <span class="mathquill ud-math">v_\pi</span>.  For each state <span class="mathquill ud-math">s \in\mathcal{S}</span>, it yields the expected return if the agent starts in state <span class="mathquill ud-math">s</span> and then uses the policy to choose its actions for all time steps.  That is, <span class="mathquill ud-math">v_\pi(s) \doteq \text{} \mathbb{E}<em>\pi[G_t|S_t=s]</span>.  We refer to <span class="mathquill ud-math">v</em>\pi(s)</span> as the <strong>value of state <span class="mathquill ud-math">s</span> under policy <span class="mathquill ud-math">\pi</span></strong>.</li>
<li>The notation <span class="mathquill ud-math">\mathbb{E}<em>\pi[\cdot]</span> is borrowed from the suggested textbook, where <span class="mathquill ud-math">\mathbb{E}</em>\pi[\cdot]</span> is defined as the expected value of a random variable, given that the agent follows policy <span class="mathquill ud-math">\pi</span>.</li>
</ul>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-bellman-equations">### Bellman Equations</h2>
<ul>
<li>The <strong>Bellman expectation equation for <span class="mathquill ud-math">v_\pi</span></strong> is: <span class="mathquill ud-math">v_\pi(s) = \text{} \mathbb{E}<em>\pi[R</em>{t+1} + \gamma v_\pi(S_{t+1})|S_t =s].</span></li>
</ul>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-optimality">### Optimality</h2>
<ul>
<li>A policy <span class="mathquill ud-math">\pi'</span> is defined to be better than or equal to a policy <span class="mathquill ud-math">\pi</span> if and only if <span class="mathquill ud-math">v_{\pi'}(s) \geq v_\pi(s)</span> for all <span class="mathquill ud-math">s\in\mathcal{S}</span>.</li>
<li>An <strong>optimal policy <span class="mathquill ud-math">\pi_<em></span></strong> satisfies <span class="mathquill ud-math">\pi_</em> \geq \pi</span> for all policies <span class="mathquill ud-math">\pi</span>.  An optimal policy is guaranteed to exist but may not be unique.</li>
<li>All optimal policies have the same state-value function <span class="mathquill ud-math">v_*</span>, called the <strong>optimal state-value function</strong>.</li>
</ul>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-action-value-functions">### Action-Value Functions</h2>
<ul>
<li>The <strong>action-value function</strong> for a policy <span class="mathquill ud-math">\pi</span> is denoted <span class="mathquill ud-math">q_\pi</span>.  For each state <span class="mathquill ud-math">s \in\mathcal{S}</span> and action <span class="mathquill ud-math">a \in\mathcal{A}</span>, it yields the expected return if the agent starts in state <span class="mathquill ud-math">s</span>, takes action <span class="mathquill ud-math">a</span>, and then follows the policy for all future time steps.  That is, <span class="mathquill ud-math">q_\pi(s,a) \doteq \mathbb{E}<em>\pi[G_t|S_t=s, A_t=a]</span>.  We refer to <span class="mathquill ud-math">q</em>\pi(s,a)</span> as the <strong>value of taking action <span class="mathquill ud-math">a</span> in state <span class="mathquill ud-math">s</span> under a policy <span class="mathquill ud-math">\pi</span></strong> (or alternatively as the <strong>value of the state-action pair <span class="mathquill ud-math">s, a</span></strong>).</li>
<li>All optimal policies have the same action-value function <span class="mathquill ud-math">q_*</span>, called the <strong>optimal action-value function</strong>.</li>
</ul>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="-optimal-policies">### Optimal Policies</h2>
<ul>
<li>Once the agent determines the optimal action-value function <span class="mathquill ud-math">q_<em></span>, it can quickly obtain an optimal policy <span class="mathquill ud-math">\pi_</em></span> by setting  <span class="mathquill ud-math">\pi_<em>(s) = \arg\max_{a\in\mathcal{A}(s)} q_</em>(s,a)</span>.</li>
</ul>
</div>

</div>
<div class="divider"></div>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.2.0</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });
    });
  </script>
</body>

</html>
