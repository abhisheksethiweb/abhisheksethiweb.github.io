WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.725
到目前为止

00:00:01.725 --> 00:00:03.990
我们查看了一个特定的策略 π

00:00:03.990 --> 00:00:07.065
计算了它对应的值函数

00:00:07.065 --> 00:00:09.884
在这道练习中 你计算了

00:00:09.884 --> 00:00:14.115
另一个不同策略的值函数 我们将此策略表示为 π′

00:00:14.115 --> 00:00:16.620
如果你观察每个值函数

00:00:16.620 --> 00:00:19.245
可能会发现某种规律

00:00:19.245 --> 00:00:23.464
请花时间对比下这些函数 可以暂停视频

00:00:23.464 --> 00:00:29.109
在现实中 这些数字可能有很多规律

00:00:29.109 --> 00:00:32.984
但是现在对我们来说最重要的规律是

00:00:32.984 --> 00:00:36.990
当我们查看任何状态并对比这两个值函数时

00:00:36.990 --> 00:00:40.109
π′ 的值函数始终大于或等于

00:00:40.109 --> 00:00:43.320
策略 π 的值函数

00:00:43.320 --> 00:00:47.295
例如 2 大于 -6

00:00:47.295 --> 00:00:50.414
3 大于 -5

00:00:50.414 --> 00:00:53.325
4 大于 -4

00:00:53.325 --> 00:00:55.905
1 等于 1

00:00:55.905 --> 00:00:59.340
也就是说 对于环境中的任何状态

00:00:59.340 --> 00:01:02.835
遵守策略 π′ 都效果更好 对吧

00:01:02.835 --> 00:01:05.894
因为无论智能体从哪个网格世界开始

00:01:05.894 --> 00:01:09.161
预期折扣回报都更大

00:01:09.162 --> 00:01:12.795
注意 智能体的目标是最大化回报

00:01:12.795 --> 00:01:17.430
因此更好的预期回报表明策略更好

00:01:17.430 --> 00:01:20.340
这就引出了一个重要的定义

00:01:20.340 --> 00:01:25.665
根据定义 如果策略 π′ 的所有状态的状态值函数

00:01:25.665 --> 00:01:29.190
大于或等于策略 π 的值函数

00:01:29.189 --> 00:01:34.009
则策略 π′ 的效果比策略 π 好或效果相同

00:01:34.010 --> 00:01:39.000
对于此定义 需要注意几个事项

00:01:39.000 --> 00:01:42.015
首先是对于任何两个策略

00:01:42.015 --> 00:01:47.305
并不一定能够判断哪个更好

00:01:47.305 --> 00:01:50.280
换句话说 它们可能无法比较

00:01:50.280 --> 00:01:52.290
但是 始终至少有一个策略

00:01:52.290 --> 00:01:56.935
比所有其他策略效果更好或效果一样

00:01:56.935 --> 00:01:59.700
我们将此策略称之为最优策略

00:01:59.700 --> 00:02:03.510
肯定存在这种策略 但是不一定是唯一的

00:02:03.510 --> 00:02:08.564
注意 最优策略正是智能体寻找的策略

00:02:08.564 --> 00:02:13.409
它是 MDP 的解决方案和实现目标的最佳策略

00:02:13.409 --> 00:02:19.615
最后 所有最优策略都具有相同的值函数 表示为 v*

00:02:19.615 --> 00:02:22.170
你可能会疑问

00:02:22.169 --> 00:02:24.030
为何不写成 Vπ*

00:02:24.030 --> 00:02:26.175
答案是这是惯例

00:02:26.175 --> 00:02:28.950
并且可能看起来更美观

00:02:28.949 --> 00:02:35.509
实际上练习中的策略是最优策略

00:02:35.509 --> 00:02:40.274
因为如果你将其与任何其他潜在策略的值函数相比

00:02:40.274 --> 00:02:43.485
它的值函数将始终大于或等于比较的值

00:02:43.485 --> 00:02:46.085
但是它不是唯一的最优策略

00:02:46.085 --> 00:02:50.550
例如 这是另一个值函数相同的策略

00:02:50.550 --> 00:02:55.385
此刻 你可能会疑问 我是如何得出这些最优策略的

00:02:55.384 --> 00:02:58.679
这个示例很简单 通过观察动态特性

00:02:58.680 --> 00:03:02.480
也许就能猜出结果

00:03:02.479 --> 00:03:05.399
但是通常并非这样

00:03:05.400 --> 00:03:08.594
因为很多 MDP 看起来复杂得多

00:03:08.594 --> 00:03:13.425
那么 我们如何得出更加复杂的 MDP 的最优策略？

00:03:13.425 --> 00:03:14.505
为了回答这一问题

00:03:14.504 --> 00:03:17.280
我们需要定义另一种类型的值函数

