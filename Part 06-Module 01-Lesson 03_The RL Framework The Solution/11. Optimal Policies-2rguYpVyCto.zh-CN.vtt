WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.734
在几个部分之前 我提到

00:00:03.734 --> 00:00:06.330
我们需要先定义动作值函数

00:00:06.330 --> 00:00:09.714
然后再讨论智能体可以如何获得最优策略

00:00:09.714 --> 00:00:13.464
我们将在后续课程中详细讲解

00:00:13.464 --> 00:00:15.419
主要概念是

00:00:15.419 --> 00:00:18.765
智能体与环境互动

00:00:18.765 --> 00:00:20.085
通过该互动

00:00:20.085 --> 00:00:23.304
估算出最优动作值函数

00:00:23.304 --> 00:00:28.454
然后智能体使用该值函数得出最优策略

00:00:28.454 --> 00:00:31.214
一切听起来有点奇怪

00:00:31.214 --> 00:00:33.090
但是在下节课 当你自己实现该流程时

00:00:33.090 --> 00:00:36.630
就会更明白

00:00:36.630 --> 00:00:39.960
暂时先别管并忽略

00:00:39.960 --> 00:00:44.910
智能体如何根据经验估算值函数这一问题

00:00:44.909 --> 00:00:49.799
尤其是 我们假设它已经知道最优动作值函数

00:00:49.799 --> 00:00:53.534
但是不知道对应的最优策略

00:00:53.534 --> 00:00:56.509
它是如何获得最优策略的呢？

00:00:56.509 --> 00:00:59.632
我们将在本视频中探讨这一问题

00:00:59.633 --> 00:01:01.140
我们已经拥有最优动作值函数

00:01:01.140 --> 00:01:06.555
你已经见过一些最优策略

00:01:06.555 --> 00:01:08.830
但是我删掉了其中的提示

00:01:08.829 --> 00:01:13.564
我们尝试根据值函数重构最优策略

00:01:13.564 --> 00:01:15.855
可能的方法是 对于每个状态

00:01:15.855 --> 00:01:20.010
我们只需选择生成最高预期回报的动作

00:01:20.010 --> 00:01:23.370
从左上角的状态开始

00:01:23.370 --> 00:01:28.640
策略是向右移动而不是向下 因为 2 大于 0

00:01:28.640 --> 00:01:32.674
向右移动后 我们看到两个 1 和一个 3

00:01:32.674 --> 00:01:36.944
3 是其中最大的值 因此我们将向右移动

00:01:36.944 --> 00:01:38.839
我们可以继续这一方式

00:01:38.840 --> 00:01:41.689
始终选择值最高的动作

00:01:41.689 --> 00:01:44.399
4 大于 2

00:01:44.400 --> 00:01:47.805
5 大于 1 或 3

00:01:47.805 --> 00:01:50.040
接下来 4 最大

00:01:50.040 --> 00:01:52.560
我们将跳过三个值为 1 的状态

00:01:52.560 --> 00:01:55.390
因为不太清楚这里该怎么办

00:01:55.390 --> 00:01:58.215
然后 2 大于 0

00:01:58.215 --> 00:02:00.840
5 大于 1

00:02:00.840 --> 00:02:03.990
回到三个值为 1 的状态

00:02:03.989 --> 00:02:06.959
实际上 为了构建最优策略

00:02:06.959 --> 00:02:08.519
这里需要作出选择

00:02:08.520 --> 00:02:14.689
智能体可以向上 向下或向右 三个选择都会产生最优策略

00:02:14.689 --> 00:02:18.370
假设测试是决定向右移动

00:02:18.370 --> 00:02:20.340
这样我们就得出了一个最优策略

00:02:20.340 --> 00:02:24.950
总结下我们刚才采取的流程

00:02:24.949 --> 00:02:28.454
如果智能体得出最优动作值函数

00:02:28.455 --> 00:02:31.903
它就能够快速获得最优策略

00:02:31.902 --> 00:02:35.819
也就是我们要寻找的 MDP 解决方案

00:02:35.819 --> 00:02:40.979
这样就引出以下问题 智能体如何找到最优值函数

00:02:40.979 --> 00:02:45.049
实际上我们将在这门课程的后续部分探索这一问题

