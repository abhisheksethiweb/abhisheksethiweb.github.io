WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.049
我们来仔细研究下线性函数逼近

00:00:04.049 --> 00:00:08.519
以及如何估算参数向量

00:00:08.519 --> 00:00:11.105
你已经知道 线性函数是所有特征乘以相应的权重

00:00:11.105 --> 00:00:14.595
并求和的结果

00:00:14.595 --> 00:00:17.120
假设你已经随机初始化这些权重

00:00:17.120 --> 00:00:21.825
并计算了状态值 v^(s,w)

00:00:21.824 --> 00:00:27.536
如何调整 W 以使逼近函数越来越接近真函数？

00:00:27.536 --> 00:00:30.580
听起来像一个数值优化问题

00:00:30.579 --> 00:00:34.917
我们使用梯度下降来找到最优参数向量

00:00:34.917 --> 00:00:38.865
首先注意 因为 v^ 是一个线性函数

00:00:38.865 --> 00:00:44.469
相对于 W 的导数就是特征向量 x(s)

00:00:44.469 --> 00:00:48.835
这也是线性函数的优势之一以及为何如此受欢迎的原因

00:00:48.835 --> 00:00:50.395
稍后我们将利用这一点

00:00:50.395 --> 00:00:54.725
现在思考下我们尝试优化的对象

00:00:54.725 --> 00:00:57.950
我们想要缩小真值函数 vπ

00:00:57.950 --> 00:01:01.785
和逼近值函数 v^ 之间的差异

00:01:01.784 --> 00:01:05.844
我们写成平方差

00:01:05.844 --> 00:01:08.739
因为我们不关心误差的符号

00:01:08.739 --> 00:01:12.084
只想使差异降低到 0

00:01:12.084 --> 00:01:17.203
更确切地来说 因为强化学习领域通常都是随机的

00:01:17.203 --> 00:01:20.454
这是预期平方差

00:01:20.454 --> 00:01:24.284
现在我们有了要优化的目标函数

00:01:24.284 --> 00:01:26.759
为此我们将使用梯度下降

00:01:26.759 --> 00:01:30.290
我们来计算该函数相对于 W 的梯度或导数

00:01:30.290 --> 00:01:34.065
使用差分链式法则

00:01:34.064 --> 00:01:39.890
结果是 -2 乘以值差异乘以 v^ 的导数

00:01:39.890 --> 00:01:44.549
之前我们提到它就是特征向量 (x,s)

00:01:44.549 --> 00:01:47.609
注意 我们去掉了这里的期望运算符

00:01:47.609 --> 00:01:51.614
侧重于单个状态 s 表示的误差梯度

00:01:51.614 --> 00:01:54.659
我们假设状态是随机选择的

00:01:54.659 --> 00:01:57.015
如果我们能够抽样足够多的状态

00:01:57.015 --> 00:01:59.709
则可以非常接近预期值

00:01:59.709 --> 00:02:02.219
我们将这个代入梯度下降更新规则的一般公式

00:02:02.219 --> 00:02:08.250
α 是步长或学习速率参数

00:02:08.250 --> 00:02:10.620
注意这里的 -1/2

00:02:10.620 --> 00:02:13.969
是为了消去导数中的 -2

00:02:13.969 --> 00:02:18.359
我们将使用这个基本公式迭代地降低每个样本状态的误差

00:02:18.360 --> 00:02:23.520
直到逼近函数和真函数几乎相等

00:02:23.520 --> 00:02:28.425
下面直观地解释下梯度下降如何优化了参数向量

00:02:28.425 --> 00:02:35.085
在每次迭代时 朝着误差的相反方向小步地更改权重

00:02:35.085 --> 00:02:37.974
因此这里的特征向量可以指出

00:02:37.974 --> 00:02:42.074
哪个方向不合适 这样我们就可以远离该方向

00:02:42.074 --> 00:02:47.369
到目前为止 我们只讨论了逼近状态值函数

00:02:47.370 --> 00:02:50.754
为了解决不基于模型的控制问题

00:02:50.754 --> 00:02:53.757
即在未知环境中采取动作

00:02:53.758 --> 00:02:57.335
我们需要逼近动作值函数

00:02:57.335 --> 00:02:59.025
为此 我们可以定义一个

00:02:59.025 --> 00:03:03.122
利用状态和动作的特征转换

00:03:03.122 --> 00:03:08.535
然后使用状态值函数中用到的梯度下降方法

00:03:08.534 --> 00:03:11.270
最后 我们看看希望逼近函数

00:03:11.270 --> 00:03:15.365
同时计算所有动作值的情况

00:03:15.365 --> 00:03:19.175
可以看做生成动作向量

00:03:19.175 --> 00:03:24.305
为此 我们可以继续使用之前的相同特征转换

00:03:24.305 --> 00:03:26.740
传入状态和动作

00:03:26.740 --> 00:03:31.189
但是如何生成不同的动作值？

00:03:31.189 --> 00:03:34.150
一种思考方式是

00:03:34.150 --> 00:03:37.295
我们尝试找到 n 个不同的动作值函数

00:03:37.294 --> 00:03:39.484
每个动作维度对应一个函数

00:03:39.485 --> 00:03:43.160
但是凭直觉 我们知道这些函数有关联性

00:03:43.159 --> 00:03:45.699
因此可以同时计算它们

00:03:45.699 --> 00:03:50.454
为此 我们可以扩展权重向量并转换为矩阵

00:03:50.455 --> 00:03:54.451
矩阵的每列模拟一个单独的线性函数

00:03:54.451 --> 00:03:57.044
但是根据状态和动作计算的共同特征

00:03:57.044 --> 00:04:00.694
使这些函数相互保持关联性

00:04:00.694 --> 00:04:03.805
如果我们的问题领域具有连续状态空间

00:04:03.805 --> 00:04:07.105
但是具有离散动作空间 这很常见

00:04:07.104 --> 00:04:10.674
我们可以轻松地选择值最大的动作

00:04:10.675 --> 00:04:13.060
没有这种平行处理的话

00:04:13.060 --> 00:04:17.959
我们需要挨个解析每个动作 然后找到最大值

00:04:17.959 --> 00:04:20.904
如果动作空间也是连续的

00:04:20.904 --> 00:04:25.179
那么这种形式使我们能够同时输出多个值

00:04:25.180 --> 00:04:27.610
例如 如果我们在开车

00:04:27.610 --> 00:04:31.830
则希望同时控制方向盘和油门

00:04:31.829 --> 00:04:35.589
线性函数逼近的主要限制条件是

00:04:35.589 --> 00:04:39.654
我们只能表示输入和输出之间的线性关系

00:04:39.654 --> 00:04:42.954
对于一维输入 则是一条线

00:04:42.954 --> 00:04:46.555
对于二维输入 变成平面 等等

00:04:46.555 --> 00:04:50.000
如果底层的值函数是非线性形状呢？

00:04:50.000 --> 00:04:54.060
线性逼近可能会产生非常糟糕的结果

00:04:54.060 --> 00:04:57.389
这时候就需要开始研究非线性函数了

