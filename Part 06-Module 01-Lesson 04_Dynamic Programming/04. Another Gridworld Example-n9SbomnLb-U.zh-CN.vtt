WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.655
我们先从一个非常小的环境开始 里面有一个智能体

00:00:05.655 --> 00:00:09.359
该环境主要由平坦的草坪组成

00:00:09.359 --> 00:00:13.169
但是其中一个地点有一座大山

00:00:13.169 --> 00:00:16.530
我们可以将四个可能的地点

00:00:16.530 --> 00:00:19.780
看做该环境的状态

00:00:19.780 --> 00:00:21.054
在每个时间点

00:00:21.054 --> 00:00:23.684
假设智能体只能上下左右移动

00:00:23.684 --> 00:00:28.829
并且只能采取不离开网格的动作

00:00:28.829 --> 00:00:33.085
箭头表示可能的移动方向

00:00:33.085 --> 00:00:35.850
智能体的目标是尽快抵达

00:00:35.850 --> 00:00:39.550
该环境的右下角

00:00:39.549 --> 00:00:42.029
我们将此任务看做阶段性任务

00:00:42.030 --> 00:00:45.798
当智能体抵达目的地时 这一阶段结束

00:00:45.798 --> 00:00:49.535
因此不用担心离开目标状态

00:00:49.534 --> 00:00:55.429
此外 假设对于大多数变动 智能体都获得奖励 -1

00:00:55.429 --> 00:00:58.560
但是如果遇到大山

00:00:58.560 --> 00:01:02.980
则获得奖励 -3 如果抵达目标状态

00:01:02.979 --> 00:01:05.125
获得奖励 5

00:01:05.125 --> 00:01:06.870
在动态规划环境中

00:01:06.870 --> 00:01:09.450
智能体知道这种奖励机制

00:01:09.450 --> 00:01:12.590
并且知道状态之间是如何变换的

00:01:12.590 --> 00:01:17.445
因此智能体已经知道关于该环境的所有信息

00:01:17.444 --> 00:01:19.054
现在呢？

00:01:19.055 --> 00:01:23.010
智能体如何利用这些信息找到最优策略？

