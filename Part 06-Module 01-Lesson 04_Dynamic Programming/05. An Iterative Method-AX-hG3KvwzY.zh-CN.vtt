WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.930
我们构建网格示例

00:00:03.930 --> 00:00:08.130
并研究如何确定对应特定策略的值函数

00:00:08.130 --> 00:00:10.915
首先 我们将枚举各个状态

00:00:10.914 --> 00:00:14.804
状态 S1 是左上角的状态

00:00:14.804 --> 00:00:18.539
然后是 S2 S3 和 S4

00:00:18.539 --> 00:00:22.349
假设我们尝试评估随机性策略

00:00:22.350 --> 00:00:26.865
即智能体从一组可能的动作里平等地选择动作

00:00:26.864 --> 00:00:29.279
例如 在状态 S1

00:00:29.280 --> 00:00:35.490
智能体可能向右或向下移动 它只是通过抛掷硬币来决定

00:00:35.490 --> 00:00:40.590
也就是说向右移动的概率是 50% 向下移动的概率也是 50%

00:00:40.590 --> 00:00:48.109
在状态 S2 它向左移动的概率是 50% 向下移动的概率是 50%

00:00:48.109 --> 00:00:50.280
状态 S3 也一样

00:00:50.280 --> 00:00:55.664
智能体向上移动的概率是 50% 向右移动的概率是 50%

00:00:55.664 --> 00:01:00.839
我们推理下该策略对应的状态值函数

00:01:00.840 --> 00:01:05.320
我们先记录关于状态 S1 的信息

00:01:05.319 --> 00:01:07.964
智能体向右移动的概率是 50%

00:01:07.965 --> 00:01:10.784
当智能体的确向右移动时

00:01:10.784 --> 00:01:14.575
它收集的预期回报可以计算为

00:01:14.575 --> 00:01:18.469
-1 加上下个状态 S2 的值

00:01:18.469 --> 00:01:20.280
在剩下的 50% 概率下

00:01:20.280 --> 00:01:24.120
智能体向下移动 得出的预期回报为

00:01:24.120 --> 00:01:29.189
-3 加上下个状态 S3 的值

00:01:29.189 --> 00:01:34.245
状态 S1 的值可以计算为这两个值的平均值

00:01:34.245 --> 00:01:38.835
因为智能体选择这两个潜在动作的概率一样

00:01:38.834 --> 00:01:45.454
你可能发现该方程式就是在状态 S1 时评估的贝尔曼方程

00:01:45.454 --> 00:01:48.060
我们看到该方程式使我们能够

00:01:48.060 --> 00:01:54.329
根据所有可能的后续状态的值表示状态 S1 的值

00:01:54.329 --> 00:01:56.640
继续看看状态 S2

00:01:56.640 --> 00:01:58.635
如果智能体向左移动

00:01:58.635 --> 00:02:02.579
预期回报是 -1 加上状态 S1 的值

00:02:02.579 --> 00:02:06.480
如果智能体向下移动

00:02:06.480 --> 00:02:12.330
预期回报是 5 加上最终状态 S4 的值

00:02:12.330 --> 00:02:15.025
为了获得状态 S2 的值

00:02:15.025 --> 00:02:18.010
我们需要对这两个值取平均值

00:02:18.009 --> 00:02:23.424
我们再次得出了贝尔曼方程 不过这次针对的是状态 S2

00:02:23.425 --> 00:02:28.170
我们可以继续按照这种方法查看状态 S3

00:02:28.169 --> 00:02:33.734
智能体可以向上或向右移动 计算这两个值的平均值

00:02:33.735 --> 00:02:39.720
最后 状态 S4 的值将始终为 0 因为它是最终状态

00:02:39.719 --> 00:02:43.125
因为如果智能体从该状态开始

00:02:43.125 --> 00:02:47.460
这一阶段将立即结束 没有任何奖励

00:02:47.460 --> 00:02:51.510
这样 我们就得出了每个状态的方程式

00:02:51.509 --> 00:02:55.649
我们可以直接对该方程组求解 得出每个状态的值

00:02:55.650 --> 00:02:57.240
当你解该方程组时

00:02:57.240 --> 00:03:01.100
会得出这些值 其中状态 S1 和最终状态均为 0

00:03:01.099 --> 00:03:06.419
另外两个状态的值均为 2

00:03:06.419 --> 00:03:11.609
对于每个状态 我们现在已经知道 如果智能体从该状态开始

00:03:11.610 --> 00:03:17.930
然后遵循均等概率随机策略 期望回报是多少

00:03:17.930 --> 00:03:21.480
现在剩下的唯一问题是通常状态空间要大很多

00:03:21.479 --> 00:03:26.504
因此直接求解方程组更加困难

00:03:26.504 --> 00:03:31.849
在这种情况下 通常使用迭代方法求解方程组会更简单

00:03:31.849 --> 00:03:34.364
因此我们不再直接求解方程组

00:03:34.365 --> 00:03:39.305
而是先猜测每个状态的值

00:03:39.305 --> 00:03:41.580
并不要求有多精准

00:03:41.580 --> 00:03:45.365
通常是将每个状态的值设为 0

00:03:45.365 --> 00:03:48.270
然后重点关注一个状态

00:03:48.270 --> 00:03:50.050
例如状态 S1

00:03:50.050 --> 00:03:53.935
我们希望更精确地猜测该状态的值

00:03:53.935 --> 00:03:56.759
为此 我们将使用之前的贝尔曼方程

00:03:56.759 --> 00:04:01.429
但是我们将调整该方程式 使其变成更新后的规则

00:04:01.430 --> 00:04:05.555
在该方程式中 大写的 V 表示对值函数的当前猜测

00:04:05.555 --> 00:04:11.469
我们将使用这个更新的规则重新猜测状态 S1 的值

00:04:11.469 --> 00:04:13.650
原理是通过猜测更新猜测

00:04:13.650 --> 00:04:16.889
使用状态 S2 和状态 S3 值的当前猜测

00:04:16.889 --> 00:04:23.769
获得状态 S1 值的新猜测

00:04:23.769 --> 00:04:29.969
我们代入状态 S2 和 S3 的估值

00:04:29.970 --> 00:04:33.180
结果状态 S1 的值的新猜测是 -2

00:04:33.180 --> 00:04:37.735
记下这个新值

00:04:37.735 --> 00:04:41.730
然后对第二个状态执行相同的流程

00:04:41.730 --> 00:04:46.770
使用状态 S1 的值更新对状态 S2 的值的猜测

00:04:46.769 --> 00:04:48.704
代入该值后

00:04:48.704 --> 00:04:55.389
得出状态 S2 的值的新猜测结果为 1 记下该值

00:04:55.389 --> 00:04:58.245
然后计算状态 S3

00:04:58.245 --> 00:05:03.949
使用状态 S1 的当前估值更新该值

00:05:03.949 --> 00:05:07.654
新的估值是 1 记下该值

00:05:07.654 --> 00:05:11.449
我们不需要更新状态 S4 的值

00:05:11.449 --> 00:05:15.779
因为它是最终状态 始终为 0

00:05:15.779 --> 00:05:20.029
但是我们可以回到第一个状态

00:05:20.029 --> 00:05:22.519
继续这一流程

00:05:22.519 --> 00:05:26.625
根据其他状态值的当前猜测结果更新对该状态的猜测

00:05:26.625 --> 00:05:31.334
此处 值更新为 -1 记录下来

00:05:31.334 --> 00:05:33.949
然后转到状态 S2 S3 等等

00:05:33.949 --> 00:05:37.670
结果发现这种迭代算法

00:05:37.670 --> 00:05:43.520
生成了越来越接近真实数值函数的估值

00:05:43.519 --> 00:05:45.979
这就是迭代策略评估算法的原理

00:05:45.980 --> 00:05:51.000
我们很快就会详细讲解该算法

