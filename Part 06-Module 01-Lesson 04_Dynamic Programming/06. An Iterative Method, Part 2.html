<!-- udacimak v1.2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>An Iterative Method, Part 2</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Dynamic Programming</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Introduction.html">01. Introduction</a>
    </li>
    <li class="">
      <a href="02. OpenAI Gym FrozenLakeEnv.html">02. OpenAI Gym: FrozenLakeEnv</a>
    </li>
    <li class="">
      <a href="03. Your Workspace.html">03. Your Workspace</a>
    </li>
    <li class="">
      <a href="04. Another Gridworld Example.html">04. Another Gridworld Example</a>
    </li>
    <li class="">
      <a href="05. An Iterative Method, Part 1.html">05. An Iterative Method, Part 1</a>
    </li>
    <li class="">
      <a href="06. An Iterative Method, Part 2.html">06. An Iterative Method, Part 2</a>
    </li>
    <li class="">
      <a href="07. Quiz An Iterative Method.html">07. Quiz: An Iterative Method</a>
    </li>
    <li class="">
      <a href="08. Iterative Policy Evaluation.html">08. Iterative Policy Evaluation</a>
    </li>
    <li class="">
      <a href="09. Implementation.html">09. Implementation</a>
    </li>
    <li class="">
      <a href="10. Mini Project DP (Parts 0 and 1).html">10. Mini Project: DP (Parts 0 and 1)</a>
    </li>
    <li class="">
      <a href="11. Action Values.html">11. Action Values</a>
    </li>
    <li class="">
      <a href="12. Implementation.html">12. Implementation</a>
    </li>
    <li class="">
      <a href="13. Mini Project DP (Part 2).html">13. Mini Project: DP (Part 2)</a>
    </li>
    <li class="">
      <a href="14. Policy Improvement.html">14. Policy Improvement</a>
    </li>
    <li class="">
      <a href="15. Implementation.html">15. Implementation</a>
    </li>
    <li class="">
      <a href="16. Mini Project DP (Part 3).html">16. Mini Project: DP (Part 3)</a>
    </li>
    <li class="">
      <a href="17. Policy Iteration.html">17. Policy Iteration</a>
    </li>
    <li class="">
      <a href="18. Implementation.html">18. Implementation</a>
    </li>
    <li class="">
      <a href="19. Mini Project DP (Part 4).html">19. Mini Project: DP (Part 4)</a>
    </li>
    <li class="">
      <a href="20. Truncated Policy Iteration.html">20. Truncated Policy Iteration</a>
    </li>
    <li class="">
      <a href="21. Implementation.html">21. Implementation</a>
    </li>
    <li class="">
      <a href="22. Mini Project DP (Part 5).html">22. Mini Project: DP (Part 5)</a>
    </li>
    <li class="">
      <a href="23. Value Iteration.html">23. Value Iteration</a>
    </li>
    <li class="">
      <a href="24. Implementation.html">24. Implementation</a>
    </li>
    <li class="">
      <a href="25. Mini Project DP (Part 6).html">25. Mini Project: DP (Part 6)</a>
    </li>
    <li class="">
      <a href="26. Check Your Understanding.html">26. Check Your Understanding</a>
    </li>
    <li class="">
      <a href="27. Summary.html">27. Summary</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">06. An Iterative Method, Part 2</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3></h3>
  <div>
  <h1 id="an-iterative-method">An Iterative Method</h1>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>In this concept, we will examine some ideas from the last video in more detail.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <figure class="figure">
    <img src="img/screen-shot-2017-09-26-at-2.18.38-pm.png" alt="" class="img img-fluid">
    <figcaption class="figure-caption">
      
    </figcaption>
  </figure>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="notes-on-the-bellman-expectation-equation">Notes on the Bellman Expectation Equation</h2>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>In the previous video, we derived one equation for each environment state.  For instance, for state <span class="mathquill ud-math">s_1</span>, we saw that:</p>
<p><span class="mathquill ud-math">v_\pi(s_1) = \frac{1}{2}(-1 + v_\pi(s_2)) + \frac{1}{2}(-3 + v_\pi(s_3))</span>.</p>
<p>We mentioned that this equation follows directly from the Bellman expectation equation for <span class="mathquill ud-math">v_\pi</span>.  </p>
<blockquote>
  <p><span class="mathquill ud-math">v_\pi(s) = \text{} \mathbb{E}<em>\pi[R</em>{t+1} + \gamma v_\pi(S_{t+1}) | S_t=s] = \sum_{a \in \mathcal{A}(s)}\pi(a|s)\sum_{s' \in \mathcal{S}, r\in\mathcal{R}}p(s',r|s,a)(r + \gamma v_\pi(s'))</span> (<strong>The Bellman expectation equation for <span class="mathquill ud-math">v_\pi</span></strong>)</p>
</blockquote>
<p>In order to see this, we can begin by looking at what the Bellman expectation equation tells us about the value of state <span class="mathquill ud-math">s_1</span> (where we just need to plug in <span class="mathquill ud-math">s_1</span> for state <span class="mathquill ud-math">s</span>).</p>
<p><span class="mathquill ud-math">v_\pi(s_1) = \sum_{a \in \mathcal{A}(s_1)}\pi(a|s_1)\sum_{s' \in \mathcal{S}, r\in\mathcal{R}}p(s',r|s_1,a)(r + \gamma v_\pi(s'))</span></p>
<p>Then, it's possible to derive the equation for state <span class="mathquill ud-math">s_1</span> by using the following:</p>
<ul>
<li><span class="mathquill ud-math">\mathcal{A}(s_1)={ \text{down}, \text{right} }</span> (<em>When in state <span class="mathquill ud-math">s_1</span>, the agent only has two potential actions: down or right.)</em></li>
<li><span class="mathquill ud-math">\pi({down}|s_1) = \pi(\text{right}|s_1) = \frac{1}{2}</span> (<em>We are currently examining the policy where the agent goes down with 50% probability and right with 50% probability when in state <span class="mathquill ud-math">s_1</span>.</em>)</li>
<li><span class="mathquill ud-math">p(s_3,-3|s_1,\text{down}) = 1</span> (and <span class="mathquill ud-math">p(s',r|s_1,\text{down}) = 0</span> if <span class="mathquill ud-math">s'\neq s_3</span> or <span class="mathquill ud-math">r\neq -3</span>) (<em>If the agent chooses to go down in state <span class="mathquill ud-math">s_1</span>, then with 100% probability, the next state is <span class="mathquill ud-math">s_3</span>, and the agent receives a reward of -3.</em>)</li>
<li><span class="mathquill ud-math">p(s_2,-1|s_1,\text{right}) = 1</span> (and <span class="mathquill ud-math">p(s',r|s_1,\text{right}) = 0</span> if <span class="mathquill ud-math">s'\neq s_2</span> or <span class="mathquill ud-math">r\neq -1</span>) (<em>If the agent chooses to go right in state <span class="mathquill ud-math">s_1</span>, then with 100% probability, the next state is <span class="mathquill ud-math">s_2</span>, and the agent receives a reward of -1.</em>)</li>
<li><span class="mathquill ud-math">\gamma = 1</span> (<em>We chose to set the discount rate to 1 in this gridworld example.</em>)</li>
</ul>
<p>If this is not entirely clear to you, please take the time now to plug in the values to derive the equation from the video.  Then, you are encouraged to repeat the same process for the other states.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h2 id="notes-on-solving-the-system-of-equations">Notes on Solving the System of Equations</h2>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <p>In the video, we mentioned that you can directly solve the system of equations:</p>
<p><span class="mathquill ud-math">v_\pi(s_1) = \frac{1}{2}(-1 + v_\pi(s_2)) + \frac{1}{2}(-3 + v_\pi(s_3))</span></p>
<p><span class="mathquill ud-math">v_\pi(s_2) = \frac{1}{2}(-1 + v_\pi(s_1)) + \frac{1}{2}(5 + v_\pi(s_4))</span></p>
<p><span class="mathquill ud-math">v_\pi(s_3) = \frac{1}{2}(-1 + v_\pi(s_1)) + \frac{1}{2}(5 + v_\pi(s_4))</span></p>
<p><span class="mathquill ud-math">v_\pi(s_4) = 0</span></p>
<p>Since the equations for <span class="mathquill ud-math">v_\pi(s_2)</span> and <span class="mathquill ud-math">v_\pi(s_3)</span> are identical, we must have that <span class="mathquill ud-math">v_\pi(s_2) = v_\pi(s_3)</span>.</p>
<p>Thus, the equations for <span class="mathquill ud-math">v_\pi(s_1)</span> and <span class="mathquill ud-math">v_\pi(s_2)</span> can be changed to: </p>
<p><span class="mathquill ud-math">v_\pi(s_1) = \frac{1}{2}(-1 + v_\pi(s_2)) + \frac{1}{2}(-3 + v_\pi(s_2)) = -2 + v_\pi(s_2)</span></p>
<p><span class="mathquill ud-math">v_\pi(s_2) = \frac{1}{2}(-1 + v_\pi(s_1)) + \frac{1}{2}(5 + 0) = 2 + \frac{1}{2}v_\pi(s_1)</span></p>
<p>Combining the two latest equations yields</p>
<p><span class="mathquill ud-math">v_\pi(s_1) = -2 + 2 + \frac{1}{2}v_\pi(s_1) = \frac{1}{2}v_\pi(s_1)</span>,</p>
<p>which implies <span class="mathquill ud-math">v_\pi(s_1)=0</span>.   Furthermore, <span class="mathquill ud-math">v_\pi(s_3)  = v_\pi(s_2) = 2 + \frac{1}{2}v_\pi(s_1) = 2 + 0 = 2</span>.</p>
<p>Thus, the state-value function is given by:</p>
<p><span class="mathquill ud-math">v_\pi(s_1) = 0</span></p>
<p><span class="mathquill ud-math">v_\pi(s_2) = 2</span></p>
<p><span class="mathquill ud-math">v_\pi(s_3) = 2</span></p>
<p><span class="mathquill ud-math">v_\pi(s_4) = 0</span></p>
<p><strong>Note</strong>.  This example serves to illustrate the fact that it is <strong><em>possible</em></strong> to <em>directly</em> solve the system of equations given by the Bellman expectation equation for <span class="mathquill ud-math">v_\pi</span>.  However, in practice, and especially for much larger Markov decision processes (MDPs), we will instead use an <em>iterative</em> solution approach.</p>
</div>

</div>
<div class="divider"></div>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://github.com/udacimak/udacimak#readme" target="_blank">udacimak v1.2.0</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });
    });
  </script>
</body>

</html>
