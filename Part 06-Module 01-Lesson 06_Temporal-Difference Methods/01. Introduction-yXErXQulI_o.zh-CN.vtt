WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.889
在这节课 你将了解时间差分或 TD 学习

00:00:04.889 --> 00:00:07.209
为了了解 TD 学习

00:00:07.209 --> 00:00:09.539
有必要讨论下

00:00:09.539 --> 00:00:13.739
通过互动解决学习问题到底是什么意思

00:00:13.740 --> 00:00:16.740
解决方案将处于遥远的未来

00:00:16.739 --> 00:00:19.709
我们发明了人工智能智能体

00:00:19.710 --> 00:00:23.234
它们能够像人类一样与世界互动

00:00:23.234 --> 00:00:25.140
为了实现这一点

00:00:25.140 --> 00:00:27.390
智能体需要从我们日常从中学习规律的

00:00:27.390 --> 00:00:31.125
在线流式数据中学习规律

00:00:31.125 --> 00:00:35.725
现实生活完全不是阶段性任务

00:00:35.725 --> 00:00:40.410
需要智能体像我们一样每天时刻都要作出决定

00:00:40.409 --> 00:00:44.454
我们从来不会停止与世界互动

00:00:44.454 --> 00:00:47.664
蒙特卡洛学习需要休息

00:00:47.664 --> 00:00:51.524
它需要结束一个阶段 以便计算回报

00:00:51.524 --> 00:00:54.725
然后用回报来估算动作值

00:00:54.725 --> 00:00:58.079
如果我们想要处理现实中更加符合实际的学习问题

00:00:58.079 --> 00:01:02.424
就需要设计不同的方法

00:01:02.424 --> 00:01:04.259
主要概念是

00:01:04.260 --> 00:01:06.450
如果智能体在玩象棋

00:01:06.450 --> 00:01:10.754
它需要在每一步都估算获胜的概率

00:01:10.754 --> 00:01:16.369
而不是等待一个阶段结束 并看看自己是否获胜了

00:01:16.370 --> 00:01:22.365
无人驾驶汽车在每个路口都要能够判断自己是否会撞车

00:01:22.364 --> 00:01:27.209
并且在必要时修改策略 避免发生车祸

00:01:27.209 --> 00:01:30.119
强调下 蒙特卡洛方法要想学习任何规律

00:01:30.120 --> 00:01:33.609
则每次都需要撞车

00:01:33.609 --> 00:01:37.689
这样的话 代价太高并且非常危险

00:01:37.689 --> 00:01:40.980
TD 学习将解决这些问题

00:01:40.980 --> 00:01:44.939
它将在每个时间步都修改预测

00:01:44.939 --> 00:01:47.864
而不是等待互动结束后才更新值

00:01:47.864 --> 00:01:53.219
你将能够使用 TD 学习解决连续性任务和阶段性任务

00:01:53.219 --> 00:01:57.075
它被广泛应用于强化学习

00:01:57.075 --> 00:02:01.620
并且是你在新闻中经常看到的前沿性算法的核心理念

00:02:01.620 --> 00:02:04.000
我们快来了解该学习方法吧

