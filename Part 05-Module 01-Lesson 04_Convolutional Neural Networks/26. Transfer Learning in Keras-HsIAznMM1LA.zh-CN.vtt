WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.173
这节课的实战项目是

00:00:02.173 --> 00:00:05.423
编写一个分类狗类品种的 CNN

00:00:05.424 --> 00:00:10.589
我们提供的数据集包含 8351 张图片

00:00:10.589 --> 00:00:15.750
每个都是一种狗狗图片 共有 133 个不同品种

00:00:15.750 --> 00:00:21.628
目标是创建一种算法 可以根据狗狗照片预测品种

00:00:21.629 --> 00:00:26.565
在此视频中 我们将演示如何使用迁移学习完成这一任务

00:00:26.565 --> 00:00:31.785
我们将使用在 ImageNet 数据集上预先训练过的 VGG-16 模型

00:00:31.785 --> 00:00:35.579
这个狗类数据集相对较小

00:00:35.579 --> 00:00:40.289
与 ImageNet 类别的子集有很高的重叠性

00:00:40.289 --> 00:00:43.185
我们从上个视频中了解到

00:00:43.185 --> 00:00:46.009
我们应该删掉网络的最后层级

00:00:46.009 --> 00:00:50.590
并添加一个新的分类层级 其中包含 133 个节点

00:00:50.590 --> 00:00:53.967
然后仅训练该层级中的权重

00:00:53.966 --> 00:00:57.344
并冻结其他层级中的所有权重

00:00:57.344 --> 00:00:59.405
在 Keras 中可以通过多种方式实现这一目标

00:00:59.405 --> 00:01:03.298
计算效率最高的是

00:01:03.298 --> 00:01:08.063
利用权重和预先训练的网络始终不会改变这一事实

00:01:08.063 --> 00:01:09.862
我们可以将每个图片

00:01:09.864 --> 00:01:17.665
穿过该网络 并在最后的 VGG-16 最大池化层那停止

00:01:17.665 --> 00:01:21.915
这样会将每个图片变成另一个三维数组

00:01:21.915 --> 00:01:26.174
然后可以保存到新的数据集中

00:01:26.174 --> 00:01:28.739
接着 当我们编写网络时

00:01:28.739 --> 00:01:35.114
我们将使用这个新数据集作为输入 我们在 Keras 中的网络将有两个层级

00:01:35.114 --> 00:01:38.665
一个输入层和一个输出层

00:01:38.665 --> 00:01:43.109
在 notebook 的第 3 行导入这个新数据集

00:01:43.108 --> 00:01:49.128
我们已经让每个图片穿过该网络 以便为你节省一些时间

00:01:49.129 --> 00:01:55.159
因此我们将此新数据集称为由瓶颈特征组成的数据集

00:01:55.159 --> 00:01:58.094
根据我们在上个视频中学到的知识

00:01:58.093 --> 00:02:03.483
我们需要创建一个传入 7x7x512 数组的模型

00:02:03.483 --> 00:02:09.525
将其扁平化为向量并提供给具有 softMax 的密集层

00:02:09.525 --> 00:02:11.490
这就是这段代码的作用

00:02:11.490 --> 00:02:13.664
我们还将总结该模型

00:02:13.663 --> 00:02:18.808
我们看到该模型具有超过 300 万的参数

00:02:18.810 --> 00:02:21.610
将需要很长的训练时间

00:02:21.610 --> 00:02:22.965
这里我们不进行训练

00:02:22.965 --> 00:02:26.354
但是如果你愿意的话 可以自己试试

00:02:26.354 --> 00:02:32.085
我们将通过全局平均池化层降低维度

00:02:32.085 --> 00:02:35.504
全局平均池化层简称 GAP 层

00:02:35.502 --> 00:02:40.589
我们发现这样可以显著减少我们需要训练的参数数量

00:02:40.590 --> 00:02:43.514
之前的模型具有超过 300 万个参数

00:02:43.514 --> 00:02:47.205
但是这个模型的参数不到 70000

00:02:47.205 --> 00:02:49.560
接着编译该模型

00:02:49.560 --> 00:02:51.193
当我们训练该模型时

00:02:51.193 --> 00:02:54.668
它的运行速度极快 甚至在 CPU 上也很快

00:02:54.669 --> 00:02:58.560
这是因为我们的模型只有两个层级

00:02:58.560 --> 00:03:01.467
如果我们没有提前计算瓶颈特征

00:03:01.467 --> 00:03:05.007
那么我们的训练流程速度会慢很多

00:03:05.008 --> 00:03:10.468
因为我们需要在每个 epoch 中都让每个图片穿过深度神经网络

00:03:10.467 --> 00:03:12.447
接着 我们加载验证准确率最高的权重

00:03:12.449 --> 00:03:18.210
当我们检查测试集的准确率时

00:03:18.210 --> 00:03:22.349
发现结果大约是 46%

00:03:22.348 --> 00:03:27.899
似乎不太理想 但是随机猜测的准确率

00:03:27.900 --> 00:03:34.074
只有大概 1/133 或不到 1% 的准确率

00:03:34.074 --> 00:03:38.469
但是你还可以在 notebook 中进一步优化

00:03:38.467 --> 00:03:42.187
这些 GAP 层级的出现时间并不久

00:03:42.187 --> 00:03:44.877
实际上 第一篇建议在 CNN 中

00:03:44.877 --> 00:03:48.787
使用 GAP 层级的论文发表于几年前

00:03:48.788 --> 00:03:51.889
甚至最近 在 2016 年中

00:03:51.889 --> 00:03:57.718
MIT 的研究人员演示指出

00:03:57.717 --> 00:03:58.947
经过分类任务训练并且具有 GAP 层级的 CNN

00:03:58.949 --> 00:04:04.514
还可以用来进行对象定位

00:04:04.514 --> 00:04:10.830
换句话说 这些 CNN 不仅能告诉我们图片中包含什么对象

00:04:10.830 --> 00:04:15.344
而且可以告诉我们对象位于图片的哪个位置

00:04:15.342 --> 00:04:18.120
如果你想尝试一些使用预先训练过的

00:04:18.120 --> 00:04:22.785
ResNet-50 模型来定位对象和图片的代码

00:04:22.785 --> 00:04:25.420
请点击下方的链接

00:04:25.420 --> 00:04:27.605
要介绍的就这么多

00:04:27.605 --> 00:04:31.350
在此项目中 除了训练利用迁移学习的模型之外

00:04:31.350 --> 00:04:36.860
你还将有机会从头编写自己的 CNN

00:04:36.860 --> 00:04:42.338
建议你尝试尽可能多的架构和想法

00:04:42.338 --> 00:04:45.658
一旦你训练识别狗类品种的 CNN 后

00:04:45.658 --> 00:04:49.095
我们将指导你在端到端算法管道中使用你的模型

00:04:49.095 --> 00:04:54.230
并且可以将该模型应用到一个有趣的在线应用中

00:04:54.230 --> 00:04:56.329
我们非常期待能够看到你所创建的模型

