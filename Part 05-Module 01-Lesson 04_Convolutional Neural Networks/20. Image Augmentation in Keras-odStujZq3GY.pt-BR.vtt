WEBVTT
Kind: captions
Language: pt-BR

00:00:00.267 --> 00:00:03.100
Quando construímos um algoritmo
para classificar objetos

00:00:03.133 --> 00:00:07.900
e imagens, há muitas
informações irrelevantes.

00:00:07.933 --> 00:00:10.600
Nós queremos
que o algoritmo determine

00:00:10.633 --> 00:00:13.767
se um objeto está presente
na imagem ou não.

00:00:13.800 --> 00:00:16.267
O tamanho do objeto
não importa,

00:00:16.300 --> 00:00:17.700
nem o ângulo,

00:00:17.733 --> 00:00:20.933
nem se eu movê-lo
para direita da imagem.

00:00:20.967 --> 00:00:23.900
Isso continuará sendo
uma imagem com um abacate.

00:00:23.933 --> 00:00:27.567
Nós queremos
que o algoritmo aprenda

00:00:27.600 --> 00:00:31.433
uma representação invariante
da imagem.

00:00:31.467 --> 00:00:34.233
Nós não queremos que o modelo
altere a previsão

00:00:34.267 --> 00:00:36.633
baseado no tamanho
do objeto.

00:00:36.667 --> 00:00:39.500
Isso é chamado
de invariância de escala.

00:00:39.533 --> 00:00:42.967
E nós não queremos que o ângulo
do objeto seja relevante.

00:00:43.600 --> 00:00:46.433
Isso é chamado
de invariância de rotação.

00:00:46.467 --> 00:00:48.800
Se eu mover a imagem
para a esquerda

00:00:48.833 --> 00:00:50.333
ou para a direita,

00:00:50.367 --> 00:00:53.067
ela continua sendo
a imagem de um abacate.

00:00:53.100 --> 00:00:56.467
Isso é chamado
de invariância de tradução.

00:00:56.500 --> 00:00:59.433
As CNNs possuem algumas

00:00:59.467 --> 00:01:02.267
invariâncias de tradução.

00:01:02.300 --> 00:01:05.500
Para ver isso, você precisa
se lembra de como calculamos

00:01:05.533 --> 00:01:07.233
camadas max pooling.

00:01:07.267 --> 00:01:09.533
Na localização
de cada janela,

00:01:09.567 --> 00:01:13.533
nós pegamos o maior pixel
de uma janela.

00:01:13.567 --> 00:01:17.600
Esse valor máximo pode ocorrer
em qualquer lugar da janela.

00:01:17.633 --> 00:01:20.967
O valor do nó max pooling
será o mesmo.

00:01:21.000 --> 00:01:23.733
Podemos traduzir a imagem
um pouco para à esquerda,

00:01:23.767 --> 00:01:26.667
para a direita,
para cima ou para baixo,

00:01:26.700 --> 00:01:30.467
desde que o valor máximo
fique dentro da janela.

00:01:30.500 --> 00:01:34.367
Aplicando muitas camadas
max pooling em uma sequência,

00:01:34.400 --> 00:01:37.467
cada uma seguida
de uma camada convolucional,

00:01:37.500 --> 00:01:40.567
nós podemos traduzir o objeto
que estiver à esquerda,

00:01:40.600 --> 00:01:43.300
em cima da imagem
ou embaixo da imagem

00:01:43.333 --> 00:01:46.967
e, ainda assim, a rede
conseguirá compreendê-lo.

00:01:47.000 --> 00:01:49.900
Este é um problema
não trivial.

00:01:49.933 --> 00:01:53.900
O computador só vê
a matriz dos pixels.

00:01:53.933 --> 00:01:56.333
Transformar a escala,
a rotação

00:01:56.367 --> 00:01:58.367
ou a posição
de um objeto na imagem

00:01:58.400 --> 00:02:01.000
afetará muito
os valores dos pixels.

00:02:01.033 --> 00:02:05.467
Nós podemos ver
a diferença nas imagens,

00:02:05.500 --> 00:02:10.233
mas como você se sairia
se tivesse um arranjo numérico?

00:02:10.267 --> 00:02:12.333
Felizmente há uma técnica
que funciona bem

00:02:12.367 --> 00:02:16.533
em tornar os algoritmos
invariantes estatisticamente,

00:02:16.567 --> 00:02:19.967
mas isso soaria
como trapaça.

00:02:20.000 --> 00:02:22.000
A ideia é assim:

00:02:22.033 --> 00:02:25.900
se você quiser que a CNN
seja invariante de rotação,

00:02:25.933 --> 00:02:29.200
então você adiciona imagens
ao conjunto de treinamento,

00:02:29.233 --> 00:02:33.300
fazendo rotações aleatórias
nas imagens de treinamento.

00:02:33.333 --> 00:02:35.800
Se você quiser mais
invariâncias de tradução,

00:02:35.833 --> 00:02:38.433
você pode adicionar
mais imagens

00:02:38.467 --> 00:02:43.100
criando traduções aleatórias
das imagens de treinamento.

00:02:43.133 --> 00:02:46.600
Assim nós expandimos
o conjunto de treinamento

00:02:46.633 --> 00:02:48.933
ampliando os dados.

00:02:48.967 --> 00:02:53.700
A ampliação de dados ajuda
a evitar superajuste.

00:02:53.733 --> 00:02:57.567
Isso é porque o modelo vê
muitas imagens novas,

00:02:57.600 --> 00:03:00.333
assim,
ele generalizará melhor,

00:03:00.367 --> 00:03:04.400
e teremos melhor desempenho
no conjunto de dados de teste.

00:03:04.433 --> 00:03:06.267
Vamos ampliar
os dados de treinamento

00:03:06.300 --> 00:03:09.500
para vermos se os dez conjuntos
de treinamento do vídeo anterior

00:03:09.533 --> 00:03:12.600
podem melhorar
a precisão de teste.

00:03:12.633 --> 00:03:14.667
Nós usaremos o bloco
de anotação do Jupyter,

00:03:14.700 --> 00:03:16.767
que você pode baixar abaixo.

00:03:16.800 --> 00:03:18.333
Após importar os dados,

00:03:18.367 --> 00:03:22.633
nós importamos uma classe Python
chamada ImageDataGenerator.

00:03:22.667 --> 00:03:26.433
Esta classe fará
as ampliações para nós.

00:03:26.467 --> 00:03:30.167
Nós só precisamos informar
o tipo de ampliação desejada.

00:03:30.200 --> 00:03:34.433
Nesta linha de código, eu criei
um gerador de imagem ampliada

00:03:34.467 --> 00:03:38.867
que muda as imagens
de forma vertical e horizontal.

00:03:38.900 --> 00:03:43.133
Ele também gira
as imagens horizontalmente.

00:03:43.800 --> 00:03:48.867
Após especificar a configuração,
eu preciso ajustá-lo aos dados.

00:03:48.900 --> 00:03:52.333
Vejamos como são algumas
das imagens ampliadas.

00:03:52.367 --> 00:03:56.767
Nós veremos ampliações
das primeiras 12 imagens

00:03:56.800 --> 00:04:00.467
que eu armazenei
no arranjo x_train_subset.

00:04:00.500 --> 00:04:03.333
Nós precisamos chamar
a função flow.

00:04:03.367 --> 00:04:06.800
Nós daremos mais detalhes
em alguns minutos.

00:04:06.833 --> 00:04:11.333
Por ora, vamos ver
as imagens ampliadas de saída.

00:04:11.367 --> 00:04:15.267
Tente ligá-las
às imagens originais.

00:04:15.300 --> 00:04:19.067
Percebeu como as imagens
ampliadas foram criadas?

00:04:19.100 --> 00:04:22.900
Quais foram deslocadas
e quais foram giradas?

00:04:22.933 --> 00:04:24.900
Antes de utilizar
as imagens ampliadas,

00:04:24.933 --> 00:04:28.133
nós precisamos definir
a arquitetura da CNN.

00:04:28.167 --> 00:04:30.733
Nós utilizaremos o modelo
do vídeo anterior.

00:04:31.400 --> 00:04:34.167
Nós compilamos o modelo,
como antes,

00:04:34.200 --> 00:04:36.167
mas, quando ajustamos a CNN

00:04:36.200 --> 00:04:38.200
para os dados de treinamento
ampliados,

00:04:38.233 --> 00:04:40.900
os comandos são
um pouco diferentes.

00:04:40.933 --> 00:04:43.700
Os passos de treinamentos
são parecidos,

00:04:43.733 --> 00:04:45.933
mas há três diferenças:

00:04:45.967 --> 00:04:50.300
primeiro "fit" foi alterado
para "fit_generator".

00:04:50.333 --> 00:04:53.700
Quando você fornece
imagens ampliadas na CNN

00:04:53.733 --> 00:04:57.600
que foram geradas
pela classe ImageDataGenerator,

00:04:57.633 --> 00:05:01.067
você deve alterar o comando fit
para "fit_generator".

00:05:02.067 --> 00:05:04.567
Segundo, no lugar
dos dados de treinamento,

00:05:04.600 --> 00:05:06.333
nós temos este comando flow

00:05:06.367 --> 00:05:09.400
que foi executado
no conjunto de treinamento.

00:05:09.433 --> 00:05:14.233
Ele faz o gerador de dados criar
lotes de imagens ampliadas.

00:05:14.267 --> 00:05:17.133
Nós vimos um desses lotes

00:05:17.167 --> 00:05:19.767
no passo anterior
do bloco de anotações.

00:05:19.800 --> 00:05:22.233
Você sempre passa
o conjunto de dados

00:05:22.267 --> 00:05:24.200
com os rótulos
correspondentes

00:05:24.233 --> 00:05:26.367
junto com a quantidade
de imagens

00:05:26.400 --> 00:05:28.800
que você quer no lote.

00:05:28.833 --> 00:05:31.733
Terceiro, nós devemos
especificar uma variável

00:05:31.767 --> 00:05:34.867
que codifica a quantidade
de passos por epoch.

00:05:34.900 --> 00:05:39.067
Configuramos com a quantidade
de amostras únicas no conjunto

00:05:39.100 --> 00:05:41.667
dividido
pelo tamanho do lote.

00:05:41.700 --> 00:05:44.733
Ao rodar esta célula de código,
você treinará o modelo.

00:05:45.400 --> 00:05:49.300
Nós carregamos os pesos
com melhor precisão de validação.

00:05:49.333 --> 00:05:50.833
Ao testar o modelo,

00:05:50.867 --> 00:05:54.167
temos precisão
de mais de 68%.

00:05:54.800 --> 00:05:59.033
Isso é melhor do que o modelo
que treinamos sem a ampliação

00:05:59.067 --> 00:06:01.000
do último vídeo.

00:06:01.033 --> 00:06:04.567
Na verdade, a ampliação
é muito utilizada

00:06:04.600 --> 00:06:06.433
em aplicações do mundo real

00:06:06.467 --> 00:06:09.800
para melhorar o desempenho
dos modelos CNN.

