WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.049
我们已经知道 CNN 由多个层级组成

00:00:04.049 --> 00:00:08.429
作为深度学习专业人士 我们设计了这一架构

00:00:08.429 --> 00:00:12.314
包括设置很多个超参数 例如窗口大小

00:00:12.314 --> 00:00:14.320
stride 和填充

00:00:14.320 --> 00:00:16.088
设置架构后

00:00:16.088 --> 00:00:19.320
我们选择损失函数和优化程序

00:00:19.320 --> 00:00:22.710
然后设置训练模型并等待

00:00:22.710 --> 00:00:25.489
我们讨论的并且在 Keras 中

00:00:25.489 --> 00:00:29.004
有提供的前沿性 CNN 架构

00:00:29.004 --> 00:00:31.769
是经过多次仔细实验几乎无限个架构

00:00:31.768 --> 00:00:36.003
和调试大量超参数后的成果

00:00:36.005 --> 00:00:41.130
它们是多年的专业知识和好几个月的努力工作带来的成果

00:00:41.130 --> 00:00:44.625
它们在庞大的 ImageNet 数据库上进行了训练

00:00:44.625 --> 00:00:49.390
经常需要好几周的训练时间 而且使用的是前沿的 GPU

00:00:49.390 --> 00:00:53.923
这就引出了一个问题：对于这些已经深入学会如何从图片中寻找规律的 CNN 架构

00:00:53.923 --> 00:00:59.603
如何调整这些 CNN 以用到我们自己的分类任务中

00:00:59.603 --> 00:01:02.819
我们如何不用从头构建一个 CNN

00:01:02.820 --> 00:01:08.174
而是运用所学的知识并传递给新的深度学习模型？

00:01:08.174 --> 00:01:12.769
我们可以通过一种叫做迁移学习的技巧顺利实现这一目标

00:01:12.769 --> 00:01:14.219
但是你可能会疑问

00:01:14.218 --> 00:01:18.673
如果你用这个在 ImageNet 数据库上经过训练的 CNN

00:01:18.674 --> 00:01:21.465
该 CNN 已经学会区分 ImageNet 中存在的

00:01:21.465 --> 00:01:25.439
1000 种不同类别的图片

00:01:25.438 --> 00:01:28.198
大部分类别都是动物

00:01:28.200 --> 00:01:31.650
水果 植物或日常物品

00:01:31.650 --> 00:01:34.230
现在假设你感兴趣的图片数据库

00:01:34.230 --> 00:01:37.290
与这些图片类别没有重叠

00:01:37.290 --> 00:01:41.185
依然能够使用这个提前训练好的 CNN 吗？

00:01:41.185 --> 00:01:44.340
甚至与新的任务有关联吗？

00:01:44.340 --> 00:01:48.275
答案是绝对肯定的

00:01:48.275 --> 00:01:51.540
实际上 我们在上个视频中看到

00:01:51.540 --> 00:01:56.650
训练好的 CNN 中的卷积过滤器按层级排列

00:01:56.650 --> 00:02:02.319
第一个层级中的过滤器通常用于检测边缘或色块

00:02:02.319 --> 00:02:07.269
第二个层级可能会检测圆圈 条纹和长方形

00:02:07.269 --> 00:02:09.908
这些依然是很普通的特征

00:02:09.907 --> 00:02:13.477
可以用来分析任何数据集中的任何图片

00:02:13.479 --> 00:02:19.069
最后的卷积层中的过滤器更加具体化

00:02:19.068 --> 00:02:21.158
如果训练数据集中有鸟类

00:02:21.157 --> 00:02:23.768
则有可以检测鸟类的过滤器

00:02:23.770 --> 00:02:25.911
如果有汽车或自行车

00:02:25.911 --> 00:02:28.514
则有可以检测轮子的过滤器 等等

00:02:28.514 --> 00:02:33.189
我们发现 可以删掉网络中最后几个

00:02:33.187 --> 00:02:38.483
非常特定于训练数据集的层级 同时保留之前的层级

00:02:38.485 --> 00:02:44.305
然后我们可以添加一两个层级 仅训练最后的层级

00:02:44.305 --> 00:02:48.460
这是一种迁移学习技巧 但是你的方法将取决于

00:02:48.460 --> 00:02:50.740
数据集的大小

00:02:50.740 --> 00:02:54.705
以及与 ImageNet 数据库的相似程度

00:02:54.705 --> 00:02:58.405
例如 如果你的数据集相对较小并且与 ImageNet 非常相似

00:02:58.405 --> 00:03:03.000
那么我们刚刚提到的技巧效果会很好

00:03:03.000 --> 00:03:05.723
顺便提下 Sebastian Thrun

00:03:05.723 --> 00:03:07.584
与斯坦福大学团队

00:03:07.585 --> 00:03:13.669
最近利用迁移学习开发了一个诊断皮肤癌的 CNN

00:03:13.669 --> 00:03:18.340
该 CNN 可以将病灶分类为良性或恶性

00:03:18.340 --> 00:03:24.033
并且在诊断某些类型的皮肤癌方面 取得的效果比皮肤科医生要高

00:03:24.032 --> 00:03:25.494
为了构建他的这一模型

00:03:25.495 --> 00:03:27.610
他使用了迁移学习方法

00:03:27.610 --> 00:03:32.320
并利用在 ImageNet 数据库上训练好的 Inception 架构

00:03:32.318 --> 00:03:33.839
首先

00:03:33.840 --> 00:03:37.525
他删掉了最后的密集连接分类层

00:03:37.525 --> 00:03:40.754
并添加了新的完全连接层

00:03:40.752 --> 00:03:43.815
这一层级的类别少了很多

00:03:43.817 --> 00:03:47.155
每个都是他想检测的疾病类别

00:03:47.155 --> 00:03:50.187
对于该网络中的所有其他层级

00:03:50.187 --> 00:03:54.655
参数都使用提前训练的值初始化

00:03:54.655 --> 00:03:57.400
在训练过程中

00:03:57.400 --> 00:04:01.750
对这些参数进一步优化 以便拟合皮肤病灶数据库

00:04:01.750 --> 00:04:04.568
该模型通过利用在 ImageNet 上提前训练好的神经网络

00:04:04.568 --> 00:04:08.573
有了很好的开端并受益很多

00:04:08.574 --> 00:04:11.465
如果你的数据集非常庞大

00:04:11.465 --> 00:04:15.115
并且与 ImageNet 数据库差别很大

00:04:15.115 --> 00:04:21.149
那么这种具有不同的最后分类层级并且细调网络参数的方法效果最好

