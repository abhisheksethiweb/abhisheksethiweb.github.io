WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.145
我们已经训练了模型

00:00:02.145 --> 00:00:06.195
我们可以加载达到最佳验证准确率的权重了

00:00:06.195 --> 00:00:09.538
当我们用测试集中的图片实验模型时

00:00:09.538 --> 00:00:14.294
我们看到模型的准确率超过了 98%

00:00:14.294 --> 00:00:19.350
结果不错 这里 MLP 是个很好的解决方案

00:00:19.350 --> 00:00:23.370
对于其他关于 MNIST 分类任务的解决方案和测试集误差

00:00:23.370 --> 00:00:28.780
请访问下面的链接

00:00:28.780 --> 00:00:30.855
你会发现最佳算法

00:00:30.855 --> 00:00:33.420
或者测试误差最小的算法

00:00:33.420 --> 00:00:38.024
是利用卷积神经网络的方法

00:00:38.024 --> 00:00:40.024
我们注意到

00:00:40.024 --> 00:00:41.755
在很多问题领域

00:00:41.755 --> 00:00:46.630
CNN 和 MLP 并不能产生理想的结果

00:00:46.630 --> 00:00:51.509
MNIST 数据集比较特殊 数据很干净并且已经预处理过

00:00:51.509 --> 00:00:54.829
所有数字图片都差不多大

00:00:54.829 --> 00:00:58.804
并在 28x28 像素网格中居中

00:00:58.804 --> 00:01:01.399
想象下 不再是分类

00:01:01.399 --> 00:01:04.489
这些非常整洁的数字图片

00:01:04.489 --> 00:01:08.540
相反 对于要处理的图片 数字可能位于任何位置

00:01:08.540 --> 00:01:12.650
并且数字有时候很小 有时候很大

00:01:12.650 --> 00:01:15.590
这样的话 任务会难很多

00:01:15.590 --> 00:01:19.114
对于现实生活中的杂乱图片数据

00:01:19.114 --> 00:01:23.334
CNN 的确比 MLP 好了很多

00:01:23.334 --> 00:01:26.299
为何在某些情况下是这种情形

00:01:26.299 --> 00:01:29.825
那是因为我们发现为了向 MLP 提供图片

00:01:29.825 --> 00:01:33.299
必须首先将图片转换为向量

00:01:33.299 --> 00:01:36.680
MLP 然后将转换后的图片

00:01:36.680 --> 00:01:40.665
处理为简单的数字向量 没有特殊结构

00:01:40.665 --> 00:01:43.474
它不知道这些图片本来是

00:01:43.474 --> 00:01:47.239
位于网格中

00:01:47.239 --> 00:01:51.635
相反 CNN 专门用于处理

00:01:51.635 --> 00:01:56.545
或发现多维数据中的规律

00:01:56.545 --> 00:02:02.150
与 MLP 不同 CNN 知道

00:02:02.150 --> 00:02:04.909
相互靠近的图片像素

00:02:04.909 --> 00:02:08.740
比离得很远的像素关系更紧密

00:02:08.740 --> 00:02:14.330
但是 MLP 和 CNN 的确有一些共同点

00:02:14.330 --> 00:02:20.349
例如 就像多层感知器模型由一堆层级组成的一样

00:02:20.348 --> 00:02:23.359
卷积神经网络也是这样

00:02:23.360 --> 00:02:27.139
并且我们不需要引入任何新的损失函数

00:02:27.139 --> 00:02:32.055
依然使用相同的优化程序来最小化所选的损失函数

00:02:32.055 --> 00:02:38.986
CNN 与 MLP 的差别是模型可以包含的隐藏层类型

00:02:38.985 --> 00:02:41.024
在接下来的几个视频中

00:02:41.025 --> 00:02:43.979
我们将介绍这些不同类型的层级

00:02:43.979 --> 00:02:47.099
并形象地说明它们在深度网络中的作用

