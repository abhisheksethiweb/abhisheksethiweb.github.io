WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.849
在这节课 我们研究了两种新的深度网络层级类型

00:00:05.849 --> 00:00:10.800
我们先介绍了卷积层 它可以检测图片中的区域性规律

00:00:10.800 --> 00:00:13.200
最大池化层出现在卷积层之后

00:00:13.199 --> 00:00:17.600
可以降低数组的维数

00:00:17.600 --> 00:00:19.020
这些数组和更加熟悉的完全连接层

00:00:19.019 --> 00:00:25.019
经常是你在 CNN 中唯一会遇到的层级

00:00:25.019 --> 00:00:31.199
在此视频中 我们将讨论如何排列这些层级 并设计 CNN 架构

00:00:31.199 --> 00:00:34.914
我们将侧重于图片分类 CNN

00:00:34.914 --> 00:00:39.884
在这种情况下 CNN 必须将图片数组作为输入

00:00:39.884 --> 00:00:43.724
如果我们要处理混乱的现实图片

00:00:43.725 --> 00:00:47.304
那么将遇到我们尚未讨论的一个难点

00:00:47.304 --> 00:00:51.405
如果我上网收集数千张或数百万张图片

00:00:51.405 --> 00:00:55.439
那么很有可能这些图片的大小各不相同

00:00:55.439 --> 00:01:02.170
和 MLP 相似 我们要讨论的 CNN 需要固定大小的输入

00:01:02.170 --> 00:01:05.820
因此 我们需要选择一个图片大小

00:01:05.819 --> 00:01:10.224
并将所有图片处理成这一大小 然后才能执行任何其他操作

00:01:10.224 --> 00:01:15.079
我们经常会重新调整图片的大小 变成正方形

00:01:15.079 --> 00:01:17.944
并使空间维度等于 2 的幂次方

00:01:17.944 --> 00:01:22.224
或者可以被 2 的幂次方整除的数

00:01:22.224 --> 00:01:24.289
在此视频及后续视频中

00:01:24.290 --> 00:01:31.885
我们要处理的数据集包含的图片均已重新调整大小 变成 32 x 32

00:01:31.885 --> 00:01:37.290
计算机会将任何图片解读为三维数组

00:01:37.290 --> 00:01:42.800
彩色图片具有宽高像素

00:01:42.799 --> 00:01:46.685
并沿着红色 绿色和蓝色通道 对应深度 3

00:01:46.685 --> 00:01:50.405
灰度图片虽然本质上是二维的

00:01:50.405 --> 00:01:54.795
但是也可以看做具有自己的宽和高 而深度是 1

00:01:54.795 --> 00:01:58.924
对于彩色或灰度图片

00:01:58.924 --> 00:02:05.049
输入数组的宽和高始终会大于深度

00:02:05.049 --> 00:02:09.229
我们的 CNN 架构的设计目标是获取该输入

00:02:09.229 --> 00:02:14.814
然后逐渐使其深度大于宽和高

00:02:14.814 --> 00:02:19.609
卷积层将用于使穿过卷积层的数组更深

00:02:19.610 --> 00:02:25.795
最大池化层将用于减小空间维度

00:02:25.794 --> 00:02:31.375
稍后我们会在本视频中详细讲解为何这么做

00:02:31.375 --> 00:02:33.155
要了解背后的工作原理

00:02:33.155 --> 00:02:37.969
看看下面的输入层 后面跟着一系列的卷积层

00:02:37.969 --> 00:02:41.270
记得在卷积层视频中我们提到

00:02:41.270 --> 00:02:46.215
这些堆叠起来的层将发现图片中的空间规律层级

00:02:46.215 --> 00:02:52.534
每个卷积层都需要我们指定超参数数量

00:02:52.534 --> 00:02:56.599
例如 过滤器经常是正方形

00:02:56.599 --> 00:03:01.909
大小范围从 2x2 到 5x5

00:03:01.909 --> 00:03:08.525
stride 通常设为 1 在 keras 中 1 是默认值

00:03:08.525 --> 00:03:11.240
对于填充 如果将其设为 'same'

00:03:11.240 --> 00:03:14.585
我们认为你将获得更好的结果

00:03:14.585 --> 00:03:17.580
在 keras 中这不是默认值

00:03:17.580 --> 00:03:23.810
将 stride 设为 1 并将填充设为 'same'

00:03:23.810 --> 00:03:27.090
将使卷积层的宽和高

00:03:27.090 --> 00:03:31.155
与上一层级的相同

00:03:31.155 --> 00:03:33.080
对于过滤器数量

00:03:33.080 --> 00:03:35.930
这个参数控制的是卷积层的深度

00:03:35.930 --> 00:03:42.060
因为层级针对每个过滤器都有一个激活映射

00:03:42.060 --> 00:03:48.379
经常我们会让过滤器数量逐渐递增

00:03:48.379 --> 00:03:51.729
因此第一个卷积层可能具有 16 个过滤器

00:03:51.729 --> 00:03:54.064
第二层将具有 32 个

00:03:54.064 --> 00:03:57.585
第三层将具有 64 个 以此类推

00:03:57.585 --> 00:04:00.140
当然 对于第一个卷积层

00:04:00.139 --> 00:04:03.844
我们还要添加一个参数“input_shape”

00:04:03.844 --> 00:04:05.639
在这个小例子中

00:04:05.639 --> 00:04:10.534
假设我们的数据集由 32x32 的彩色图片组成

00:04:10.534 --> 00:04:16.709
我们将在所有卷积层中使用 relu 激活函数

00:04:16.709 --> 00:04:18.604
如果按照这一流程操作

00:04:18.605 --> 00:04:21.710
这会让数组的深度逐渐增大

00:04:21.709 --> 00:04:25.614
但是不会修改宽度和高度

00:04:25.615 --> 00:04:29.345
输入层和该序列中的所有层级一样

00:04:29.345 --> 00:04:32.005
宽和高为 32

00:04:32.004 --> 00:04:40.284
但是深度从输入层的 3 增大为 16 再增大为 64

00:04:40.285 --> 00:04:42.980
是的 我们希望增大深度

00:04:42.980 --> 00:04:47.775
但是我们还希望减小高度和宽度

00:04:47.774 --> 00:04:50.745
这时候最大池化层就派上用场了

00:04:50.745 --> 00:04:56.300
它们通常紧跟在序列中的一个或两个卷积层后面

00:04:56.300 --> 00:04:57.650
最常见的设置是

00:04:57.649 --> 00:05:01.914
使用大小为 2 的过滤器

00:05:01.915 --> 00:05:04.754
这样可以使空间维度

00:05:04.754 --> 00:05:08.264
变成上一层级的一半

00:05:08.264 --> 00:05:12.990
这样 通过组合使用卷积层和最大池化层

00:05:12.990 --> 00:05:16.050
我们就能够获得很深

00:05:16.050 --> 00:05:19.925
且空间维度很小的数组

00:05:19.925 --> 00:05:22.290
我们通过在 keras 中输入代码

00:05:22.290 --> 00:05:25.225
看看维度是如何变化的 再次检查下

00:05:25.225 --> 00:05:28.740
和预期的一样 卷积层将数组的深度

00:05:28.740 --> 00:05:33.490
从 3 变成了 16 再变成 32 最终变成 64

00:05:33.490 --> 00:05:37.350
最大池化层将空间维度从 32 减小为 16

00:05:37.350 --> 00:05:41.655
再减小为 8 最终变成 4

00:05:41.654 --> 00:05:46.875
这种层级序列发现了图片中包含的空间规律

00:05:46.875 --> 00:05:53.399
它逐渐获取空间数据 并将数组转换为

00:05:53.399 --> 00:05:56.384
包含图片内容的表示

00:05:56.384 --> 00:06:00.480
所有空间信息最终会丢失

00:06:00.480 --> 00:06:02.240
在原始图片中

00:06:02.240 --> 00:06:06.569
很容易知道各个像素与其他哪些像素相邻

00:06:06.569 --> 00:06:11.879
查看在长长的序列之后图片最终是如何转换的

00:06:11.879 --> 00:06:16.475
就会发现数组中的条目与哪个项目相邻不重要了

00:06:16.475 --> 00:06:22.830
相反 数组可以回答以下问题：图片中有轮子吗？

00:06:22.829 --> 00:06:25.629
有眼睛吗？

00:06:25.629 --> 00:06:29.339
有毛茸茸的腿或尾巴吗？

00:06:29.339 --> 00:06:31.859
一旦我们获得的表示

00:06:31.860 --> 00:06:35.415
不再具有图片中的空间信息

00:06:35.415 --> 00:06:38.970
我们就可以扁平化该数组

00:06:38.970 --> 00:06:44.995
并将其提供给一个或多个全连接层 判断图片中包含什么对象

00:06:44.995 --> 00:06:49.634
例如 如果在最后一个最大池化层中发现轮子

00:06:49.634 --> 00:06:53.564
那么该全连接层会转换该信息

00:06:53.564 --> 00:06:58.230
并预测图片中有汽车的概率更高

00:06:58.230 --> 00:07:00.560
如果有眼睛

00:07:00.560 --> 00:07:02.694
毛茸茸的腿和尾巴

00:07:02.694 --> 00:07:06.459
那么输出层会获取该信息

00:07:06.459 --> 00:07:10.534
并推断图片中可能包含狗狗

00:07:10.535 --> 00:07:13.310
当然 模型中的这些理解信息

00:07:13.310 --> 00:07:17.480
并不是我们提前指定的

00:07:17.480 --> 00:07:22.520
而是模型在训练过程中通过反向传播了解的

00:07:22.519 --> 00:07:27.274
我们指定的这个结构只是向模型提供了一个

00:07:27.274 --> 00:07:30.079
使其能更好地训练的结构

00:07:30.079 --> 00:07:33.919
从而能够更准确地分类对象

00:07:33.920 --> 00:07:37.000
我们将此结构输入到 keras 中

00:07:37.000 --> 00:07:40.725
我在这里仅添加了三行代码

00:07:40.725 --> 00:07:44.600
首先 将最后一个最大池化层扁平化为向量

00:07:44.600 --> 00:07:47.660
然后添加两个密集层

00:07:47.660 --> 00:07:53.900
最后一个层级具有 softmax 激活函数 以便返回概率

00:07:53.899 --> 00:07:56.959
这里 我将最终密集层的节点设为 10 个

00:07:56.959 --> 00:08:01.924
因为我们的数据集将具有 10 个不同的对象类别

00:08:01.925 --> 00:08:03.329
经常还会向隐藏完全连接层

00:08:03.329 --> 00:08:09.175
和 CNN 架构提供 relu 激活函数

00:08:09.175 --> 00:08:11.060
我在这里也添加了

00:08:11.060 --> 00:08:15.685
我们将在下个视频中进一步处理该架构

00:08:15.685 --> 00:08:20.024
我在本视频中介绍的理论只是帮你起步而已

00:08:20.024 --> 00:08:21.929
要自己设计模型

00:08:21.930 --> 00:08:24.870
你需要亲自尝试各种架构

00:08:24.870 --> 00:08:29.050
和不同的超参数

00:08:29.050 --> 00:08:31.530
深度学习是一种需要实践操作的领域

00:08:31.529 --> 00:08:37.174
所以不要怕麻烦 不去实践 并且不要担心违背了规则

00:08:37.174 --> 00:08:39.649
尽量去尝试不同的事物

00:08:39.649 --> 00:08:42.029
提出问题并通过实验来回答你的问题

00:08:42.029 --> 00:08:45.919
而不是仅仅思考

00:08:45.919 --> 00:08:48.284
如果这是你第一次训练 CNN

00:08:48.284 --> 00:08:51.139
那么需要一段时间才能有直观的感觉

00:08:51.139 --> 00:08:56.759
但是要继续尝试 如果一开始的想法失败了 也不要气馁

