WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.490
CIFAR-10 是一个热门的数据集 其中包含 60,000 个小图片

00:00:05.490 --> 00:00:09.230
每个都描绘了一种对象 共有 10 个类别

00:00:09.230 --> 00:00:13.800
我们将使用该数据集进行图片分类

00:00:13.800 --> 00:00:18.955
建议你按照下面链接的 Jupyter notebook 跟着操作

00:00:18.954 --> 00:00:22.500
将此数据集导入 keras 相对比较简单

00:00:22.500 --> 00:00:26.879
我们需要导入一个 python 模块

00:00:26.879 --> 00:00:32.129
然后 只需一行代码 就能开始训练并用相应的标签测试图片

00:00:32.130 --> 00:00:36.385
我们可视化这些训练图片的一个小子集

00:00:36.384 --> 00:00:38.484
和预期的一样 数据集中有船只

00:00:38.484 --> 00:00:44.939
狗狗 马以及其他对象类别

00:00:44.939 --> 00:00:48.989
和之前一样 我们添加一个预处理步骤

00:00:48.990 --> 00:00:53.929
将每个图片中的每个像素除以 255

00:00:53.929 --> 00:00:58.490
现在每个图片数组的条目是在 0 到 1 之间

00:00:58.490 --> 00:01:02.255
我们还拿出了验证集

00:01:02.255 --> 00:01:07.045
所以现在是 45,000 张训练图片和 5,000 张验证图片

00:01:07.045 --> 00:01:12.599
再留出 10,000 张图片 在训练之后测试网络的准确性

00:01:12.599 --> 00:01:15.104
每个图片都很小

00:01:15.105 --> 00:01:19.210
只有 32 像素高和 32 像素宽

00:01:19.209 --> 00:01:25.579
每个都是彩色图片 计算机将它们解读为深度为 3 的数组

00:01:25.579 --> 00:01:29.625
我们将训练的第一个模型是普通的 Vanilla 神经网络

00:01:29.625 --> 00:01:33.209
我们首先需要将每个图片扁平化为向量

00:01:33.209 --> 00:01:37.689
所有空间信息将丢失

00:01:37.689 --> 00:01:42.295
然后将该向量提供给具有两个隐藏层的 MLP

00:01:42.295 --> 00:01:44.143
注意参数的数量

00:01:44.143 --> 00:01:47.064
超过 305 万个

00:01:47.064 --> 00:01:49.569
你觉得该方法可行吗？

00:01:49.569 --> 00:01:55.814
随机猜测的准确率大概在 10% 左右

00:01:55.814 --> 00:01:58.045
你认为 MLP 的准确率会超过这一值吗？

00:01:58.045 --> 00:01:59.750
如果能超过 超过多少？

00:01:59.750 --> 00:02:04.965
我们将使用和之前一样的损失函数和优化程序

00:02:04.965 --> 00:02:08.340
然后对模型训练 20 个 epoch

00:02:08.340 --> 00:02:12.215
并保存验证准确率最高的权重

00:02:12.215 --> 00:02:14.009
如果你自己运行 notebook 

00:02:14.009 --> 00:02:19.299
可以增加 epoch 数量或修改其他超参数

00:02:19.300 --> 00:02:20.955
训练完毕后

00:02:20.955 --> 00:02:24.090
我们可以加载保存的模型权重

00:02:24.090 --> 00:02:29.134
测试集的准确率大概是 40%

00:02:29.134 --> 00:02:34.769
比随机猜测的效果好 但是希望 CNN 的效果好很多

00:02:34.770 --> 00:02:36.965
我们打开另一个 notebook 

00:02:36.965 --> 00:02:40.969
所有导入和预处理步骤都一样

00:02:40.969 --> 00:02:45.564
我们在 notebook 的第五步定义 CNN 架构

00:02:45.564 --> 00:02:50.009
根据之前的视频 CNN 应该看起来很熟悉

00:02:50.009 --> 00:02:52.319
图片首先经过一系列的卷积层和最大池化层

00:02:52.319 --> 00:02:57.794
旨在挤压出空间信息

00:02:57.794 --> 00:03:02.814
然后扁平化图片 并添加几个完全连接层

00:03:02.814 --> 00:03:06.437
唯一的区别是 dropout 层

00:03:06.437 --> 00:03:09.734
我们添加了这些 dropout 层 以便尽量避免过拟合

00:03:09.735 --> 00:03:15.264
注意 这个网络用到的参数比我们刚刚训练的 MLP 少了很多

00:03:15.264 --> 00:03:19.860
但是希望它能更好地完成分类任务

00:03:19.860 --> 00:03:24.095
继续使用相同的损失函数和优化程序

00:03:24.094 --> 00:03:29.205
对模型训练 100 个 epoch 批次大小为 32

00:03:29.205 --> 00:03:34.260
加载验证准确率最高的模型权重

00:03:34.259 --> 00:03:40.215
我们的 CNN 测试准确率大概为 66%

00:03:40.215 --> 00:03:44.620
相对于刚刚训练的 MLP 而言 改善了很多

00:03:44.620 --> 00:03:49.784
当然 该 CNN 还有很多改进的余地

00:03:49.784 --> 00:03:51.270
建议你继续改进它

00:03:51.270 --> 00:03:53.950
这将是个很好的学习经历

00:03:53.949 --> 00:03:56.394
顺便提下 在 2015 年

00:03:56.395 --> 00:03:59.400
网上出现了一项竞赛

00:03:59.400 --> 00:04:03.855
数据科学家针对 CIFAR-10 数据集图片分类任务展开竞争

00:04:03.854 --> 00:04:10.099
获胜的架构是 CNN 测试准确率超过了 95%

00:04:10.099 --> 00:04:13.854
在 GPU 上的训练时间为 90 小时

00:04:13.854 --> 00:04:16.394
如果你想了解这一架构

00:04:16.394 --> 00:04:19.279
请参阅下方的链接

