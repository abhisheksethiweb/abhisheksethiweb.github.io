WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.359
当我们设计算法来分类对象和图片时

00:00:03.359 --> 00:00:07.955
我们需要处理大量的不相关信息

00:00:07.955 --> 00:00:10.259
我们只是希望算法能判断

00:00:10.259 --> 00:00:13.544
图片中是否存在某个对象

00:00:13.544 --> 00:00:17.713
对象的大小和角度并不重要

00:00:17.713 --> 00:00:21.018
或者对象是否跑到了图片的右侧

00:00:21.018 --> 00:00:23.788
依然是一张牛油果图片

00:00:23.789 --> 00:00:27.300
换句话说 我们希望算法能学习

00:00:27.300 --> 00:00:31.579
图片的不变表示

00:00:31.579 --> 00:00:36.829
我们不希望模型根据对象的大小而改变预测

00:00:36.829 --> 00:00:39.615
这叫做标度不变性

00:00:39.615 --> 00:00:43.868
类似地 我们不希望对象的角度造成影响

00:00:43.868 --> 00:00:46.585
这叫做旋转不变性

00:00:46.585 --> 00:00:49.170
如果我向左或向右稍微移动图片

00:00:49.170 --> 00:00:53.262
依然是牛油果图片

00:00:53.262 --> 00:00:56.439
这叫做平移不变性

00:00:56.439 --> 00:01:02.084
CNN 具有一些内置的平移不变性

00:01:02.084 --> 00:01:07.480
为此 你需要首先回忆下我们是如何计算最大池化层的

00:01:07.480 --> 00:01:09.644
在每个窗口位置

00:01:09.644 --> 00:01:13.500
我们都获取窗口中最大的像素

00:01:13.500 --> 00:01:17.430
这个最大值会出现在窗口中的任何位置

00:01:17.430 --> 00:01:21.030
最大池化层节点的值可能是相同的

00:01:21.030 --> 00:01:24.989
如果我们将图片向左、右、上、下平移

00:01:24.989 --> 00:01:30.299
只要最大值保持在窗口中 节点的值就可能相同

00:01:30.299 --> 00:01:34.275
在每个卷积层后面紧跟着一个最大池化层地

00:01:34.275 --> 00:01:37.305
应用很多最大池化层的效果是

00:01:37.305 --> 00:01:40.709
我们能将对象平移到最左侧

00:01:40.709 --> 00:01:42.030
最上方 最底部

00:01:42.030 --> 00:01:47.189
神经网络依然能理解该图片吗？

00:01:47.188 --> 00:01:50.158
这真的是一个不可忽视的问题

00:01:50.159 --> 00:01:53.694
计算机只看到一个像素矩阵

00:01:53.694 --> 00:01:56.715
变换对象的大小 旋转角度 在图片中的位置

00:01:56.715 --> 00:02:01.144
对像素值有很大的影响

00:02:01.144 --> 00:02:04.620
作为人类 我们可以非常清晰地看出图片中的区别

00:02:04.620 --> 00:02:07.019
但是如果只给出对应的数组数字

00:02:07.019 --> 00:02:10.145
该怎么区别呢

00:02:10.145 --> 00:02:12.659
幸运的是 有一种技巧

00:02:12.657 --> 00:02:16.274
可以很好地让算法更加具有统计不变性

00:02:16.275 --> 00:02:20.093
但是感觉有点像在欺骗

00:02:20.092 --> 00:02:21.899
原理是

00:02:21.900 --> 00:02:25.710
如果要 CNN 具有旋转不变性

00:02:25.710 --> 00:02:29.120
那么可以向训练集中添加一些图片

00:02:29.120 --> 00:02:33.389
这些图片对训练图片进行随机旋转

00:02:33.389 --> 00:02:35.925
如果希望具有平移不变性

00:02:35.925 --> 00:02:39.300
那么可以通过随机地平移训练图片

00:02:39.300 --> 00:02:43.050
向训练集中添加新的图片

00:02:43.050 --> 00:02:48.599
这么做时 我们通过增强数据扩展了数据集

00:02:48.598 --> 00:02:53.783
数据增强还可以帮助我们避免过拟合

00:02:53.782 --> 00:02:57.537
这是因为模型看到了很多新的图片

00:02:57.538 --> 00:03:00.448
因此应该更能够广义化

00:03:00.449 --> 00:03:04.129
测试集中的效果应该更好

00:03:04.127 --> 00:03:07.532
我们增强训练集 看看上个视频中的 10 个数据集

00:03:07.532 --> 00:03:12.062
看看是否能够改善测试准确率

00:03:12.062 --> 00:03:16.407
我们将使用可在下方下载的 Jupyter notebook 

00:03:16.407 --> 00:03:18.317
导入数据后

00:03:18.318 --> 00:03:23.068
我们导入一个 python 类 叫做 ImageDataGenerator

00:03:23.068 --> 00:03:26.549
该类将帮助我们完成所有增强工作

00:03:26.550 --> 00:03:29.909
我们只需告诉它我们想要什么样的增强

00:03:29.907 --> 00:03:31.428
在这行代码中

00:03:31.429 --> 00:03:34.710
我创建了一个增强图片生成器

00:03:34.710 --> 00:03:38.889
它将随机地水平和垂直移动图片

00:03:38.889 --> 00:03:43.805
还会随机地水平翻转图片

00:03:43.805 --> 00:03:46.185
指定配置后

00:03:46.185 --> 00:03:48.750
需要添加到我的数据中

00:03:48.750 --> 00:03:52.080
我们看看其中一些增强图片的效果

00:03:52.080 --> 00:03:54.629
我们将只可视化前 12 张训练图片的增强效果

00:03:54.627 --> 00:04:00.613
我将其存储在了 x_train_subset 数组中

00:04:00.615 --> 00:04:03.284
现在只需调用 flow 函数

00:04:03.282 --> 00:04:06.947
稍后我们将详细了解该函数

00:04:06.949 --> 00:04:11.375
暂时先看看输出的增强图片

00:04:11.375 --> 00:04:15.400
试着将它们匹配到相应的原始图片

00:04:15.400 --> 00:04:18.841
可以看出增强图片是如何创建的吗？

00:04:18.841 --> 00:04:22.454
哪些图片平移了 哪些翻转了

00:04:22.454 --> 00:04:25.014
在使用这些增强图片之前

00:04:25.014 --> 00:04:28.028
我们需要定义我们的 CNN 架构

00:04:28.028 --> 00:04:31.425
我们将使用上个视频中的模型

00:04:31.425 --> 00:04:33.853
和之前一样编译该模型

00:04:33.853 --> 00:04:38.278
但是现在当我们用增强训练数据拟合 CNN 时

00:04:38.278 --> 00:04:41.017
命令有点不同了

00:04:41.019 --> 00:04:46.079
训练步骤几乎一样 但是有三点区别

00:04:46.079 --> 00:04:50.430
首先 fit 变成了 fit_generator

00:04:50.430 --> 00:04:53.910
只要拟合通过 ImageDataGenerator 类

00:04:53.910 --> 00:04:57.569
生成的 CNN 增强图片

00:04:57.569 --> 00:05:01.550
就始终需要将 fit 命令改成 fit_generator

00:05:01.550 --> 00:05:05.110
其次 在训练集中

00:05:05.110 --> 00:05:09.595
我们对训练集执行了这个 flow 命令

00:05:09.595 --> 00:05:14.300
它使数据生成器创建一批批增强图片

00:05:14.300 --> 00:05:19.584
我们在 notebook 中的上一步可视化了其中一个批次

00:05:19.584 --> 00:05:22.778
你将始终传入训练集和对应的标签

00:05:22.778 --> 00:05:28.894
以及批次中的图片数量

00:05:28.894 --> 00:05:34.750
第三 我们需要指定一个变量 表示每个 epoch 的步长数量

00:05:34.750 --> 00:05:41.785
通常设为数据集中的唯一样本数量除以批次大小

00:05:41.785 --> 00:05:43.295
通过运行这段代码

00:05:43.295 --> 00:05:45.009
我们可以训练模型

00:05:45.009 --> 00:05:49.120
加载验证准确率最高的权重

00:05:49.120 --> 00:05:50.829
当我们测试该模型时

00:05:50.829 --> 00:05:55.040
测试准确率超过了 68%

00:05:55.040 --> 00:06:01.050
与上个视频中没有增强图片的模型相比 有了改进

00:06:01.050 --> 00:06:04.720
实际上 现实中经常会使用增强处理

00:06:04.720 --> 00:06:10.000
来改善 CNN 模型的效果

